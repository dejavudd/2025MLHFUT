{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是一个基于PyTorch实现的DSFD（Dual Shot Face Detector）人脸检测模型训练脚本，专门针对暗光场景进行了优化。该实现采用了双阶段检测架构，结合了图像增强网络（RetinexNet）和检测网络，以提高模型在低光照条件下的性能。代码支持多种基础网络（VGG、ResNet系列和专门的暗光场景模型），并实现了完整的分布式训练流程，包括数据加载、模型训练、验证和模型保存等功能。在训练过程中，使用了多任务损失函数（检测损失和图像增强损失），并采用SSIM（结构相似性）评估图像质量。代码还实现了动态学习率调整、梯度裁剪、权重衰减等优化策略，并支持断点续训和TensorBoard可视化。通过结合图像增强和检测网络，该实现显著提高了模型在暗光环境下的检测性能，适合在WIDER FACE等大规模数据集上进行训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "核心库导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load train.py\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "# ===================== 导入必要的库 =====================\n",
    "# 基础库\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.tensorboard import SummaryWriter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from data.config import cfg  # 配置文件，包含模型参数和训练设置\n",
    "from layers.modules import MultiBoxLoss, EnhanceLoss  # 损失函数模块\n",
    "from data.widerface import WIDERDetection, detection_collate  # 数据集加载和预处理\n",
    "from models.factory import build_net, basenet_factory  # 模型构建工厂\n",
    "from models.enhancer import RetinexNet  # 图像增强网络\n",
    "from utils.DarkISP import Low_Illumination_Degrading  # 低光照图像生成工具\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个部分定义了训练过程中所有可配置的参数，包括模型选择、训练批次大小、学习率等关键超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='DSFD face Detector Training With Pytorch')\n",
    "train_set = parser.add_mutually_exclusive_group()\n",
    "# 训练相关参数\n",
    "parser.add_argument('--batch_size',\n",
    "                    default=4, type=int,\n",
    "                    help='训练批次大小，影响内存使用和训练速度')\n",
    "parser.add_argument('--model',\n",
    "                    default='dark', type=str,\n",
    "                    choices=['dark', 'vgg', 'resnet50', 'resnet101', 'resnet152'],\n",
    "                    help='选择训练模型，dark为暗光场景专用模型')\n",
    "parser.add_argument('--resume',\n",
    "                    default=None, type=str,\n",
    "                    help='恢复训练的检查点文件路径，用于断点续训')\n",
    "parser.add_argument('--num_workers',\n",
    "                    default=0, type=int,\n",
    "                    help='数据加载的工作进程数，建议设置为CPU核心数的2-4倍')\n",
    "parser.add_argument('--cuda',\n",
    "                    default=True, type=bool,\n",
    "                    help='是否使用CUDA进行训练，建议在有GPU的情况下开启')\n",
    "parser.add_argument('--lr', '--learning-rate',\n",
    "                    default=5e-4, type=float,\n",
    "                    help='初始学习率，影响模型收敛速度和稳定性')\n",
    "parser.add_argument('--momentum',\n",
    "                    default=0.9, type=float,\n",
    "                    help='SGD优化器的动量值，用于加速收敛和减少震荡')\n",
    "parser.add_argument('--weight_decay',\n",
    "                    default=5e-4, type=float,\n",
    "                    help='SGD优化器的权重衰减，用于防止过拟合')\n",
    "parser.add_argument('--gamma',\n",
    "                    default=0.1, type=float,\n",
    "                    help='SGD学习率更新的gamma值，控制学习率衰减速度')\n",
    "parser.add_argument('--multigpu',\n",
    "                    default=True, type=bool,\n",
    "                    help='是否使用多GPU训练，可以加速训练过程')\n",
    "parser.add_argument('--save_folder',\n",
    "                    default='weights/',\n",
    "                    help='保存检查点模型的目录，用于存储训练过程中的模型')\n",
    "parser.add_argument('--local_rank',\n",
    "                    type=int,\n",
    "                    help='分布式训练的本地rank，用于多GPU训练时的进程标识')\n",
    "\n",
    "args = parser.parse_args()\n",
    "global local_rank\n",
    "local_rank = args.local_rank\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个部分设置了分布式训练的环境，对于多GPU训练至关重要，确保数据正确分配到各个GPU；以及对数据加载器设置，这个部分负责数据的加载和预处理，使用分布式采样器确保数据在多GPU训练时正确分配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if 'LOCAL_RANK' not in os.environ:\n",
    "    os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "# 初始化分布式进程组\n",
    "import torch.distributed as dist\n",
    "dist.init_process_group(backend='nccl')\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if args.cuda:\n",
    "        gpu_num = torch.cuda.device_count()\n",
    "        if local_rank == 0:\n",
    "            print('使用 {} 个GPU'.format(gpu_num))\n",
    "        rank = int(os.environ['RANK'])\n",
    "        torch.cuda.set_device(rank % gpu_num)\n",
    "    if not args.cuda:\n",
    "        print(\"警告: 您有CUDA设备，但未使用CUDA。\\n使用 --cuda 参数以获得最佳训练速度。\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "\n",
    "save_folder = os.path.join(args.save_folder, args.model)\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "\n",
    "train_dataset = WIDERDetection(cfg.FACE.TRAIN_FILE, mode='train')\n",
    "val_dataset = WIDERDetection(cfg.FACE.VAL_FILE, mode='val')\n",
    "\n",
    "# 创建分布式采样器\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, shuffle=True)\n",
    "train_loader = data.DataLoader(train_dataset, args.batch_size,\n",
    "                               num_workers=args.num_workers,\n",
    "                               collate_fn=detection_collate,\n",
    "                               sampler=train_sampler,\n",
    "                               pin_memory=True)\n",
    "\n",
    "val_batchsize = args.batch_size\n",
    "val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, val_batchsize,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=detection_collate,\n",
    "                             sampler=val_sampler,\n",
    "                             pin_memory=True)\n",
    "\n",
    "min_loss = np.inf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练函数是整个训练脚本的核心部分，负责模型的初始化、训练循环、验证和模型保存等关键功能。在训练过程中，首先初始化模型和优化器，加载预训练权重或恢复训练状态。训练循环中，对输入图像进行预处理和增强，包括生成暗光图像和使用增强网络处理图像。在前向传播阶段，模型同时处理暗光图像和正常图像，计算检测损失和增强损失。损失函数包括第一阶段的定位损失和置信度损失、第二阶段的定位损失和置信度损失，以及图像增强相关的重建损失和SSIM损失。在反向传播阶段，使用梯度裁剪防止梯度爆炸，并通过优化器更新模型参数。训练过程中定期进行验证，保存最佳模型和检查点，并使用TensorBoard记录训练指标和可视化结果。整个训练过程支持分布式训练，可以充分利用多GPU资源加速训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train():\n",
    "    \"\"\"\n",
    "    主训练函数\n",
    "    包含模型初始化、训练循环、验证和模型保存等功能\n",
    "    \n",
    "    训练流程：\n",
    "    1. 初始化模型和优化器\n",
    "    2. 加载预训练权重或恢复训练\n",
    "    3. 训练循环：\n",
    "       - 数据预处理和增强\n",
    "       - 前向传播\n",
    "       - 损失计算\n",
    "       - 反向传播和优化\n",
    "       - 定期验证和保存\n",
    "    4. 模型评估和保存\n",
    "    \"\"\"\n",
    "    # 初始化TensorBoard写入器\n",
    "    writer = None\n",
    "\n",
    "    # 计算每个epoch的迭代次数\n",
    "    per_epoch_size = len(train_dataset) // (args.batch_size * torch.cuda.device_count())\n",
    "    start_epoch = 0\n",
    "    iteration = 0\n",
    "    step_index = 0\n",
    "\n",
    "    # 创建TensorBoard日志目录\n",
    "    log_dir = os.path.join('runs', args.model, time.strftime('%Y%m%d-%H%M%S'))\n",
    "    if local_rank == 0 and not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    # 初始化TensorBoard\n",
    "    if local_rank == 0:\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "        print(f\"TensorBoard日志将保存到: {log_dir}\")\n",
    "\n",
    "    # ===================== 模型初始化 =====================\n",
    "    # 创建基础网络和DSFD网络\n",
    "    basenet = basenet_factory(args.model)  # 创建基础网络（如VGG、ResNet等）\n",
    "    dsfd_net = build_net('train', cfg.NUM_CLASSES, args.model)  # 创建DSFD检测网络\n",
    "    net = dsfd_net\n",
    "    net_enh = RetinexNet()  # 创建图像增强网络\n",
    "    net_enh.load_state_dict(torch.load('/data1/home/chenruoyu/DAI-Net/weights/decomp.pth'))  # 加载预训练的增强网络权重\n",
    "\n",
    "    # 加载预训练权重或恢复训练\n",
    "    if args.resume:\n",
    "        if local_rank == 0:\n",
    "            print('恢复训练，加载 {}...'.format(args.resume))\n",
    "        start_epoch = net.load_weights(args.resume)\n",
    "        iteration = start_epoch * per_epoch_size\n",
    "    else:\n",
    "        base_weights = torch.load(args.save_folder + basenet)\n",
    "        if local_rank == 0:\n",
    "            print('加载基础网络 {}'.format(args.save_folder + basenet))\n",
    "        if args.model == 'vgg' or args.model == 'dark':\n",
    "            net.vgg.load_state_dict(base_weights)  # 加载VGG或DarkNet基础网络权重\n",
    "        else:\n",
    "            net.resnet.load_state_dict(base_weights)  # 加载ResNet基础网络权重\n",
    "\n",
    "    # 初始化网络权重\n",
    "    if not args.resume:\n",
    "        if local_rank == 0:\n",
    "            print('初始化权重...')\n",
    "        # 初始化各个模块的权重\n",
    "        net.extras.apply(net.weights_init)  # 特征提取模块\n",
    "        net.fpn_topdown.apply(net.weights_init)  # FPN自顶向下路径\n",
    "        net.fpn_latlayer.apply(net.weights_init)  # FPN横向连接\n",
    "        net.fpn_fem.apply(net.weights_init)  # 特征增强模块\n",
    "        net.loc_pal1.apply(net.weights_init)  # 第一阶段定位预测\n",
    "        net.conf_pal1.apply(net.weights_init)  # 第一阶段置信度预测\n",
    "        net.loc_pal2.apply(net.weights_init)  # 第二阶段定位预测\n",
    "        net.conf_pal2.apply(net.weights_init)  # 第二阶段置信度预测\n",
    "        net.ref.apply(net.weights_init)  # 特征细化模块\n",
    "\n",
    "    # ===================== 优化器设置 =====================\n",
    "    # 设置学习率，根据batch size和GPU数量进行缩放\n",
    "    lr = args.lr * np.round(np.sqrt(args.batch_size / 4 * torch.cuda.device_count()), 4)\n",
    "    param_group = []\n",
    "    # 为不同模块设置不同的学习率\n",
    "    param_group += [{'params': dsfd_net.vgg.parameters(), 'lr': lr}]  # 基础网络\n",
    "    param_group += [{'params': dsfd_net.extras.parameters(), 'lr': lr}]  # 特征提取\n",
    "    param_group += [{'params': dsfd_net.fpn_topdown.parameters(), 'lr': lr}]  # FPN自顶向下\n",
    "    param_group += [{'params': dsfd_net.fpn_latlayer.parameters(), 'lr': lr}]  # FPN横向连接\n",
    "    param_group += [{'params': dsfd_net.fpn_fem.parameters(), 'lr': lr}]  # 特征增强\n",
    "    param_group += [{'params': dsfd_net.loc_pal1.parameters(), 'lr': lr}]  # 第一阶段定位\n",
    "    param_group += [{'params': dsfd_net.conf_pal1.parameters(), 'lr': lr}]  # 第一阶段置信度\n",
    "    param_group += [{'params': dsfd_net.loc_pal2.parameters(), 'lr': lr}]  # 第二阶段定位\n",
    "    param_group += [{'params': dsfd_net.conf_pal2.parameters(), 'lr': lr}]  # 第二阶段置信度\n",
    "    param_group += [{'params': dsfd_net.ref.parameters(), 'lr': lr / 10.}]  # 特征细化（使用较小的学习率）\n",
    "\n",
    "    optimizer = optim.SGD(param_group, lr=lr, momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "\n",
    "    # ===================== GPU和分布式设置 =====================\n",
    "    if args.cuda:\n",
    "        if args.multigpu:\n",
    "            # 使用DistributedDataParallel进行多GPU训练\n",
    "            net = torch.nn.parallel.DistributedDataParallel(net.cuda(), find_unused_parameters=True)\n",
    "            net_enh = torch.nn.parallel.DistributedDataParallel(net_enh.cuda())\n",
    "        cudnn.benchmark = True  # 启用cuDNN自动调优\n",
    "\n",
    "    # 初始化损失函数\n",
    "    criterion = MultiBoxLoss(cfg, args.cuda)  # 目标检测损失\n",
    "    criterion_enhance = EnhanceLoss()  # 图像增强损失\n",
    "    if local_rank == 0:\n",
    "        print('加载WIDER数据集...')\n",
    "        print('使用指定的参数:')\n",
    "        print(args)\n",
    "\n",
    "    # 调整学习率\n",
    "    for step in cfg.LR_STEPS:\n",
    "        if iteration > step:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, args.gamma, step_index)\n",
    "\n",
    "    # ===================== 训练循环 =====================\n",
    "    net_enh.eval()  # 设置增强网络为评估模式\n",
    "    net.train()  # 设置检测网络为训练模式\n",
    "    for epoch in range(start_epoch, cfg.EPOCHES):\n",
    "        losses = 0\n",
    "\n",
    "        for batch_idx, (images, targets, _) in enumerate(train_loader):\n",
    "            # 数据预处理\n",
    "            images = Variable(images.cuda() / 255.)  # 归一化图像\n",
    "            targetss = [Variable(ann.cuda(), requires_grad=False) for ann in targets]  # 处理目标框\n",
    "            # 生成暗光图像\n",
    "            img_dark = torch.empty(size=(images.shape[0], images.shape[1], images.shape[2], images.shape[3])).cuda()\n",
    "            for i in range(images.shape[0]):\n",
    "                img_dark[i], _ = Low_Illumination_Degrading(images[i])\n",
    "\n",
    "            # 学习率调整\n",
    "            if iteration in cfg.LR_STEPS:\n",
    "                step_index += 1\n",
    "                adjust_learning_rate(optimizer, args.gamma, step_index)\n",
    "\n",
    "            # 前向传播\n",
    "            t0 = time.time()\n",
    "            # 使用增强网络处理图像\n",
    "            R_dark_gt, I_dark = net_enh(img_dark)  # 获取暗光图像的反射图和光照图\n",
    "            R_light_gt, I_light = net_enh(images)  # 获取正常图像的反射图和光照图\n",
    "\n",
    "            # 使用检测网络进行预测\n",
    "            out, out2, loss_mutual = net(img_dark, images, I_dark.detach(), I_light.detach())\n",
    "            R_dark, R_light, R_dark_2, R_light_2 = out2\n",
    "\n",
    "            # 计算损失\n",
    "            optimizer.zero_grad()\n",
    "            # 计算检测损失\n",
    "            loss_l_pa1l, loss_c_pal1 = criterion(out[:3], targetss)  # 第一阶段损失\n",
    "            loss_l_pa12, loss_c_pal2 = criterion(out[3:], targetss)  # 第二阶段损失\n",
    "            # 计算增强损失\n",
    "            loss_enhance = criterion_enhance([R_dark, R_light, R_dark_2, R_light_2, I_dark.detach(), I_light.detach()], images, img_dark) * 0.1\n",
    "            # 计算重建损失和SSIM损失\n",
    "            loss_enhance2 = F.l1_loss(R_dark, R_dark_gt.detach()) + F.l1_loss(R_light, R_light_gt.detach()) + (\n",
    "                        1. - ssim(R_dark, R_dark_gt.detach())) + (1. - ssim(R_light, R_light_gt.detach()))\n",
    "\n",
    "            # 总损失\n",
    "            loss = loss_l_pa1l + loss_c_pal1 + loss_l_pa12 + loss_c_pal2 + loss_enhance2 + loss_enhance + loss_mutual\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            loss.backward()\n",
    "            # 梯度裁剪，防止梯度爆炸\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=35, norm_type=2)\n",
    "            optimizer.step()\n",
    "            t1 = time.time()\n",
    "            losses += loss.item()\n",
    "\n",
    "            # 打印训练信息\n",
    "            if iteration % 100 == 0:\n",
    "                tloss = losses / (batch_idx + 1)\n",
    "                if local_rank == 0:\n",
    "                    print('计时器: %.4f' % (t1 - t0))\n",
    "                    print('epoch:' + repr(epoch) + ' || iter:' +\n",
    "                          repr(iteration) + ' || Loss:%.4f' % (tloss))\n",
    "                    print('->> pal1 置信度损失:{:.4f} || pal1 定位损失:{:.4f}'.format(\n",
    "                        loss_c_pal1.item(), loss_l_pa1l.item()))\n",
    "                    print('->> pal2 置信度损失:{:.4f} || pal2 定位损失:{:.4f}'.format(\n",
    "                        loss_c_pal2.item(), loss_l_pa12.item()))\n",
    "                    print('->>学习率:{}'.format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "                    # TensorBoard可视化\n",
    "                    if iteration % 500 == 0:\n",
    "                        original_img = images[0].cpu()\n",
    "                        dark_img = img_dark[0].cpu()\n",
    "                        enhanced_img = R_dark[0].detach().cpu()\n",
    "\n",
    "                        writer.add_image('Images/原始图像', original_img, iteration)\n",
    "                        writer.add_image('Images/暗光图像', dark_img, iteration)\n",
    "                        writer.add_image('Images/增强图像', enhanced_img, iteration)\n",
    "\n",
    "            # 保存检查点\n",
    "            if iteration != 0 and iteration % 5000 == 0:\n",
    "                if local_rank == 0:\n",
    "                    print('保存状态, iter:', iteration)\n",
    "                    file = 'dsfd_' + repr(iteration) + '.pth'\n",
    "                    torch.save(dsfd_net.state_dict(),\n",
    "                               os.path.join(save_folder, file))\n",
    "            iteration += 1\n",
    "\n",
    "        # 验证\n",
    "        if (epoch + 1) >= 0:\n",
    "            val(epoch, net, dsfd_net, net_enh, criterion, writer)\n",
    "        if iteration >= cfg.MAX_STEPS:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证函数负责在验证集上评估模型的性能，是监控训练进度和保存最佳模型的关键组件。在验证过程中，首先将模型设置为评估模式，然后在验证集上进行前向传播。对于每个批次的数据，函数会生成对应的暗光图像，并通过模型进行预测。验证过程中计算第一阶段的定位损失和置信度损失，以及第二阶段的定位损失和置信度损失，这些损失共同构成总验证损失。函数会汇总所有GPU上的损失，计算平均验证损失，并通过TensorBoard记录验证结果。如果当前验证损失低于历史最低损失，函数会保存当前模型作为最佳模型。此外，函数还会定期保存检查点，包含当前训练轮次和模型权重，以便后续恢复训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def val(epoch, net, dsfd_net, net_enh, criterion, writer=None):\n",
    "    \"\"\"\n",
    "    验证函数\n",
    "    在验证集上评估模型性能\n",
    "    \n",
    "    验证流程：\n",
    "    1. 设置模型为评估模式\n",
    "    2. 在验证集上进行前向传播\n",
    "    3. 计算验证损失\n",
    "    4. 保存最佳模型\n",
    "    5. 记录验证结果\n",
    "    \"\"\"\n",
    "    net.eval()  # 设置模型为评估模式\n",
    "    step = 0\n",
    "    losses = torch.tensor(0.).cuda()\n",
    "    t1 = time.time()\n",
    "\n",
    "    # 验证循环\n",
    "    for batch_idx, (images, targets, img_paths) in enumerate(val_loader):\n",
    "        if args.cuda:\n",
    "            images = Variable(images.cuda() / 255.)\n",
    "            targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n",
    "        else:\n",
    "            images = Variable(images / 255.)\n",
    "            targets = [Variable(ann, volatile=True) for ann in targets]\n",
    "        \n",
    "        # 生成暗光图像\n",
    "        img_dark = torch.stack([Low_Illumination_Degrading(images[i])[0] for i in range(images.shape[0])], dim=0)\n",
    "        # 前向传播\n",
    "        out, R = net.module.test_forward(img_dark)\n",
    "\n",
    "        # 计算损失\n",
    "        loss_l_pa1l, loss_c_pal1 = criterion(out[:3], targets)  # 第一阶段损失\n",
    "        loss_l_pa12, loss_c_pal2 = criterion(out[3:], targets)  # 第二阶段损失\n",
    "        loss = loss_l_pa12 + loss_c_pal2  # 总损失\n",
    "\n",
    "        losses += loss.item()\n",
    "        step += 1\n",
    "    \n",
    "    # 汇总所有GPU的损失\n",
    "    dist.reduce(losses, 0, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    # 计算平均损失\n",
    "    tloss = losses / step / torch.cuda.device_count()\n",
    "    t2 = time.time()\n",
    "    \n",
    "    # 打印验证结果\n",
    "    if local_rank == 0:\n",
    "        print('计时器: %.4f' % (t2 - t1))\n",
    "        print('验证 epoch:' + repr(epoch) + ' || Loss:%.4f' % (tloss))\n",
    "\n",
    "        # TensorBoard记录\n",
    "        if writer is not None:\n",
    "             writer.add_scalar('Loss/验证损失', tloss, epoch)\n",
    "\n",
    "             # 验证集图像可视化\n",
    "             if epoch % 1 == 0:\n",
    "                 original_val_img = images[0].cpu()\n",
    "                 enhanced_val_img = R[0].detach().cpu()\n",
    "\n",
    "                 writer.add_image('验证图像/原始图像', original_val_img, epoch)\n",
    "                 writer.add_image('验证图像/增强图像', enhanced_val_img, epoch)\n",
    "\n",
    "    # 保存最佳模型\n",
    "    global min_loss\n",
    "    if tloss < min_loss:\n",
    "        if local_rank == 0:\n",
    "            print('保存最佳模型, epoch', epoch)\n",
    "            torch.save(dsfd_net.state_dict(), os.path.join(save_folder, 'dsfd.pth'))\n",
    "        min_loss = tloss\n",
    "\n",
    "    # 保存检查点\n",
    "    states = {\n",
    "        'epoch': epoch,\n",
    "        'weight': dsfd_net.state_dict(),\n",
    "    }\n",
    "    if local_rank == 0:\n",
    "        torch.save(states, os.path.join(save_folder, 'dsfd_checkpoint.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该函数接收三个关键参数：优化器对象、学习率衰减系数（gamma）和当前训练步骤。在训练过程中，当达到预定义的步骤时，函数会被调用，将优化器中所有参数组的学习率乘以衰减系数gamma，实现学习率的动态调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"\n",
    "    调整学习率\n",
    "    在每个指定步骤将学习率衰减gamma倍\n",
    "    \n",
    "    参数:\n",
    "        optimizer: 优化器对象\n",
    "        gamma: 学习率衰减系数\n",
    "        step: 当前步骤\n",
    "    \"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * gamma\n",
    "\n",
    "# ===================== 主函数 =====================\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpupytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
