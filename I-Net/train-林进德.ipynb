{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcb09dd4-2abf-4e45-a12e-dde6a9653b4c",
   "metadata": {},
   "source": [
    "# 模块导入 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805d64c-6c42-4a7c-a8d2-2bb64e1de607",
   "metadata": {},
   "source": [
    "## 介绍：本系统采用两阶段联合训练框架。主干使用基于DSFD的人脸检测模型，同时引入IAT高曝光图像矫正模型作为曝光伪标签生成器。训练过程中，IAT模型提供高曝光场景下的曝光修正结果作为辅助监督信号，通过L1增强损失与检测主损失联合优化，提升检测模型在极端曝光条件下的鲁棒性与泛化能力。整体训练在多GPU分布式环境中完成，并结合多阶段学习率调整与损失平衡策略控制训练稳定性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048f216e-7e91-42f2-b247-81cca89f4327",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.autograd import Variable\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import torch.distributed as dist\n",
    "\n",
    "from models.enhancer import RetinexNet\n",
    "from models.factory import build_net, basenet_factory\n",
    "from layers.modules import EnhanceLoss\n",
    "from data.config import cfg\n",
    "from data.widerface import WIDERDetection, detection_collate\n",
    "from model.IAT_main import IAT\n",
    "from utils.brightgISP import Low_Illumination_Degrading\n",
    "\n",
    "import sys\n",
    "sys.path.append('/data1/home/chenruoyu/IAD-Net/jiandan/IAT_enhance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c469e-1b09-45ca-bed5-1a64d184728f",
   "metadata": {},
   "source": [
    "# 训练参数配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5f2793-21e5-47f2-bdde-4e7efed4f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='增强模型训练')\n",
    "\n",
    "parser.add_argument('--batch_size', default=4, type=int)\n",
    "parser.add_argument('--resume', default=None, type=str)\n",
    "parser.add_argument('--num_workers', default=0, type=int)\n",
    "parser.add_argument('--cuda', default=True, type=bool)\n",
    "parser.add_argument('--lr', default=5e-4, type=float)\n",
    "parser.add_argument('--momentum', default=0.9, type=float)\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float)\n",
    "parser.add_argument('--gamma', default=0.1, type=float)\n",
    "parser.add_argument('--multigpu', default=True, type=bool)\n",
    "parser.add_argument('--save_folder', default='weights/')\n",
    "parser.add_argument('--local-rank', type=int)\n",
    "\n",
    "args = parser.parse_args()\n",
    "local_rank = args.local_rank\n",
    "os.environ['LOCAL_RANK'] = str(args.local_rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351e18b-7e16-49d4-a3fb-395c931390b2",
   "metadata": {},
   "source": [
    "# 分布式训练初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0ce2e9-0b5a-453b-bb68-fb5cbca0d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(backend='nccl')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    if args.cuda:\n",
    "        gpu_num = torch.cuda.device_count()\n",
    "        rank = int(os.environ['RANK'])\n",
    "        torch.cuda.set_device(rank % gpu_num)\n",
    "    else:\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9514394-135d-454b-bd8b-f38052dbfdd7",
   "metadata": {},
   "source": [
    "# 数据集与数据加载器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80c49f-dcc9-42ed-8f1c-c97ac2e92b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = os.path.join(args.save_folder, 'IAT')\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "train_dataset = WIDERDetection(cfg.FACE.TRAIN_FILE, mode='train')\n",
    "val_dataset = WIDERDetection(cfg.FACE.VAL_FILE, mode='val')\n",
    "\n",
    "train_sampler = data.distributed.DistributedSampler(train_dataset, shuffle=True)\n",
    "val_sampler = data.distributed.DistributedSampler(val_dataset, shuffle=True)\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, args.batch_size, num_workers=args.num_workers,\n",
    "                                collate_fn=detection_collate, sampler=train_sampler, pin_memory=True)\n",
    "val_loader = data.DataLoader(val_dataset, args.batch_size, num_workers=0,\n",
    "                              collate_fn=detection_collate, sampler=val_sampler, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b787d-fbc7-4786-a8ad-485ae187cc07",
   "metadata": {},
   "source": [
    "# 模型初始化部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b057fa-5262-4155-baed-c5a23273122c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    writer = None\n",
    "    per_epoch_size = len(train_dataset) // (args.batch_size * torch.cuda.device_count())\n",
    "    start_epoch, iteration, step_index = 0, 0, 0\n",
    "\n",
    "    log_dir = os.path.join('runs', 'IAT', time.strftime('%Y%m%d-%H%M%S'))\n",
    "    if local_rank == 0 and not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "    if local_rank == 0:\n",
    "        writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    basenet = basenet_factory('dark')\n",
    "    dsfd_net = build_net('train', cfg.NUM_CLASSES, 'dark')\n",
    "    net = dsfd_net\n",
    "\n",
    "    IAT_model = IAT(type='exp').cuda()\n",
    "    IAT_model.load_state_dict(torch.load('/data1/home/chenruoyu/IAD-Net/jiandan/IAT_enhance/quanzhong/1.pth'))\n",
    "    IAT_model.eval()\n",
    "\n",
    "    if args.resume:\n",
    "        start_epoch = net.load_weights(args.resume)\n",
    "        iteration = start_epoch * per_epoch_size\n",
    "    else:\n",
    "        base_weights = torch.load(args.save_folder + basenet)\n",
    "        if args.model == 'vgg' or args.model == 'dark':\n",
    "            net.vgg.load_state_dict(base_weights)\n",
    "        else:\n",
    "            net.resnet.load_state_dict(base_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b23f4-b471-4114-b6ca-396f5b3a66ec",
   "metadata": {},
   "source": [
    "# 权重初始化与优化器配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533e2de6-23fd-4fd8-92b6-495a27b9dec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "  if not args.resume:\n",
    "        net.extras.apply(net.weights_init)\n",
    "        net.fpn_topdown.apply(net.weights_init)\n",
    "        net.fpn_latlayer.apply(net.weights_init)\n",
    "        net.fpn_fem.apply(net.weights_init)\n",
    "        net.ref.apply(net.weights_init)\n",
    "\n",
    "    lr = args.lr * np.round(np.sqrt(args.batch_size / 4 * torch.cuda.device_count()), 4)\n",
    "    lr = lr * 0.001\n",
    "\n",
    "    param_group = []\n",
    "    param_group += [{'params': dsfd_net.vgg.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.extras.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.fpn_topdown.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.fpn_latlayer.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.fpn_fem.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.ref.parameters(), 'lr': lr / 10.}]\n",
    "    optimizer = optim.SGD(param_group, lr=lr, momentum=args.momentum, weight_decay=args.weight_decay)\n",
    "\n",
    "    if args.cuda and args.multigpu:\n",
    "        net = torch.nn.parallel.DistributedDataParallel(dsfd_net.cuda(), find_unused_parameters=True)\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    criterion_enhance = EnhanceLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb216822-8f79-48c7-90b5-314a2218fbd5",
   "metadata": {},
   "source": [
    "# 训练主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693c29ad-3a20-4bcc-a389-8b4fcf86f3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " net.train()\n",
    "    for epoch in range(start_epoch, cfg.EPOCHES):\n",
    "        losses = 0\n",
    "        for batch_idx, (images, targets, _) in enumerate(train_loader):\n",
    "            images = Variable(images.cuda())\n",
    "            targets = [Variable(ann.cuda(), requires_grad=False) for ann in targets]\n",
    "\n",
    "            with torch.no_grad():\n",
    "                _, _, R_light_gt = IAT_model(images / 255.)\n",
    "\n",
    "            out = net(images)\n",
    "            loss_l, loss_c = 0, 0  # 这里只保留增强部分\n",
    "            detection_loss = 0\n",
    "            enhance_loss = F.l1_loss(out['enhanced'], R_light_gt.detach())\n",
    "            total_loss = detection_loss + 0.1 * enhance_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            losses += total_loss.item()\n",
    "\n",
    "            if iteration % 100 == 0 and local_rank == 0:\n",
    "                tloss = losses / (batch_idx + 1)\n",
    "                print('epoch:{} iter:{} Loss:{:.4f}'.format(epoch, iteration, tloss))\n",
    "\n",
    "                if writer:\n",
    "                    writer.add_scalar('Loss/train', tloss, iteration)\n",
    "\n",
    "            iteration += 1\n",
    "\n",
    "        val(epoch, net, dsfd_net, IAT_model, writer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3619d43-ebe7-4de9-b24a-bb20d7d4073b",
   "metadata": {},
   "source": [
    "# 验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f3e767-f538-4941-9884-95ff5f139b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch, net, dsfd_net, IAT_model, writer=None):\n",
    "    net.eval()\n",
    "    step = 0\n",
    "    losses = torch.tensor(0.).cuda()\n",
    "\n",
    "    for batch_idx, (images, targets, img_paths) in enumerate(val_loader):\n",
    "        images = Variable(images.cuda() / 255.)\n",
    "        img_dark = torch.stack([Low_Illumination_Degrading(images[i])[0] for i in range(images.shape[0])], dim=0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _, R_val = net.module.test_forward(img_dark)\n",
    "            _, _, R_dark_gt_val = IAT_model(img_dark)\n",
    "            loss_val_enhance = F.l1_loss(R_val, R_dark_gt_val.detach()) + (1. - ssim(R_val, R_dark_gt_val.detach()))\n",
    "            loss = loss_val_enhance\n",
    "\n",
    "        losses += loss.item()\n",
    "        step += 1\n",
    "\n",
    "    dist.reduce(losses, 0, op=dist.ReduceOp.SUM)\n",
    "    tloss = losses / step / torch.cuda.device_count()\n",
    "\n",
    "    if local_rank == 0:\n",
    "        print('验证集: epoch:{} Loss:{:.4f}'.format(epoch, tloss))\n",
    "        if writer:\n",
    "            writer.add_scalar('Loss/val', tloss, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16a7e2-c03c-4fef-8cfa-4eb8262004ed",
   "metadata": {},
   "source": [
    "# 学习率动态调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dee298a-c1e8-4a0d-85ea-c9e3fdcacfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] *= gamma\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin",
   "language": "python",
   "name": "lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
