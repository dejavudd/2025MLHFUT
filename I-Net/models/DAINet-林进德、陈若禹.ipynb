{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba34e81-7b1d-435e-beaf-adddd7681fe6",
   "metadata": {},
   "source": [
    "# 基本模块导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f39969-b94f-4c88-b258-cb6422618d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "\n",
    "from layers import *  # DSFD中使用的工具层，如 L2Norm, PriorBox, Detect 等\n",
    "from data.config import cfg  # 配置文件，包含模型参数、训练参数等"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f62e90-3752-407c-bd8a-020184fabe94",
   "metadata": {},
   "source": [
    "# 插值模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c5294-4a2f-46a2-84b2-f1120e521690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14936da-3265-4d2f-ba6c-8d55b9ac7ed5",
   "metadata": {},
   "source": [
    "# 特征增强模块 (FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac31e8-0f6a-4762-b498-84af4533e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEM(nn.Module):\n",
    "    \"\"\"\n",
    "    输入特征通道被均匀划分到三路分支：\n",
    "      - 分支一：单层膨胀卷积\n",
    "      - 分支二：两层膨胀卷积堆叠\n",
    "      - 分支三：三层膨胀卷积堆叠\n",
    "    多路特征融合增强特征提取能力\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes):\n",
    "        super(FEM, self).__init__()\n",
    "        inter_planes = in_planes // 3\n",
    "        inter_planes1 = in_planes - 2 * inter_planes\n",
    "\n",
    "        self.branch1 = nn.Conv2d(in_planes, inter_planes, kernel_size=3, padding=3, dilation=3)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, inter_planes, kernel_size=3, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_planes, inter_planes, kernel_size=3, padding=3, dilation=3)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, inter_planes1, kernel_size=3, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_planes1, inter_planes1, kernel_size=3, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_planes1, inter_planes1, kernel_size=3, padding=3, dilation=3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x1, x2, x3), dim=1)\n",
    "        return F.relu(out, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546fc9a-4f06-480a-96dc-28b2c6ef9f58",
   "metadata": {},
   "source": [
    "# 整体 DSFD 主体架构 (包含增强+检测联合)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3c9ff-fae6-4f84-a0c6-0d4af75bf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSFD(nn.Module):\n",
    "    \"\"\"\n",
    "    DSFD主干网络：\n",
    "    - 基于VGG的基础特征提取器\n",
    "    - 两阶段（PAL1 / PAL2）检测头\n",
    "    - 特征金字塔模块 (FPN + FEM)\n",
    "    - 反射增强模块 (Reflectance Decoder)\n",
    "    - 蒸馏对齐模块 (KL Divergence)\n",
    "    \"\"\"\n",
    "    def __init__(self, phase, base, extras, fem, head1, head2, num_classes):\n",
    "        super(DSFD, self).__init__()\n",
    "        self.phase = phase  # 训练 or 测试\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # VGG主干网络\n",
    "        self.vgg = nn.ModuleList(base)\n",
    "\n",
    "        # 多层特征归一化 (L2Norm，防止数值震荡)\n",
    "        self.L2Normof1 = L2Norm(256, 10)\n",
    "        self.L2Normof2 = L2Norm(512, 8)\n",
    "        self.L2Normof3 = L2Norm(512, 5)\n",
    "\n",
    "        # 扩展额外层（更深层特征提取）\n",
    "        self.extras = nn.ModuleList(extras)\n",
    "\n",
    "        # FPN顶向下(top-down)融合 + 侧向连接(lateral) + FEM模块\n",
    "        self.fpn_topdown = nn.ModuleList(fem[0])\n",
    "        self.fpn_latlayer = nn.ModuleList(fem[1])\n",
    "        self.fpn_fem = nn.ModuleList(fem[2])\n",
    "\n",
    "        # 融合后的特征图再次L2归一化\n",
    "        self.L2Normef1 = L2Norm(256, 10)\n",
    "        self.L2Normef2 = L2Norm(512, 8)\n",
    "        self.L2Normef3 = L2Norm(512, 5)\n",
    "\n",
    "        # 两阶段检测分支（PAL1、PAL2）\n",
    "        self.loc_pal1 = nn.ModuleList(head1[0])\n",
    "        self.conf_pal1 = nn.ModuleList(head1[1])\n",
    "        self.loc_pal2 = nn.ModuleList(head2[0])\n",
    "        self.conf_pal2 = nn.ModuleList(head2[1])\n",
    "\n",
    "        # 🌟 反射增强解码分支 (Reflectance Decoder)\n",
    "        self.ref = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Interpolate(2),  # 上采样放大两倍\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()     # 输出范围限制在[0,1]\n",
    "        )\n",
    "\n",
    "        # 🌟 蒸馏损失模块 (用于增强特征对齐)\n",
    "        self.KL = DistillKL(T=4.0)\n",
    "\n",
    "        # 测试阶段加入softmax分类器和最终Detect解码器\n",
    "        if self.phase == 'test':\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            self.detect = Detect(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb5d71-5a53-459a-9f75-8aa7615b6320",
   "metadata": {},
   "source": [
    "# 自定义特征上采样并乘法融合函数（FPN用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cac4cd-310e-4800-9e63-d11079863572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upsample_prod(self, x, y):\n",
    "        _, _, H, W = y.size()\n",
    "        return F.upsample(x, size=(H, W), mode='bilinear') * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce56492-509a-4745-a5c4-95e846cd966d",
   "metadata": {},
   "source": [
    "# 只用于增强解码（纯反射分支推理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d1029-59af-4671-af39-e47cffbb719e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def enh_forward(self, x):\n",
    "        x = x[:1]  # 仅处理第一张图片，通常训练单张增强\n",
    "        for k in range(5):\n",
    "            x = self.vgg[k](x)\n",
    "        R = self.ref(x)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb453957-65c5-49e4-96ac-f0be0f269b2f",
   "metadata": {},
   "source": [
    "# 完整测试前向推理 (检测与增强联合输出)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f9366-8f9a-4347-8db8-28d7b76f31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def test_forward(self, x):\n",
    "        size = x.size()[2:]  # 输入图像尺寸\n",
    "        pal1_sources, pal2_sources = [], []  # 两阶段特征缓存\n",
    "        loc_pal1, conf_pal1 = [], []         # PAL1预测输出\n",
    "        loc_pal2, conf_pal2 = [], []         # PAL2预测输出\n",
    "\n",
    "        # ===== VGG 特征抽取阶段 =====\n",
    "        for k in range(16):\n",
    "            x = self.vgg[k](x)\n",
    "            if k == 4:  # conv4_3特征提前提取，用于增强模块\n",
    "                x_ = x\n",
    "        R = self.ref(x_[0:1])  # 增强模块反射解码输出\n",
    "\n",
    "        of1 = x\n",
    "        s = self.L2Normof1(of1)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(16, 23):\n",
    "            x = self.vgg[k](x)\n",
    "        of2 = x\n",
    "        s = self.L2Normof2(of2)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(23, 30):\n",
    "            x = self.vgg[k](x)\n",
    "        of3 = x\n",
    "        s = self.L2Normof3(of3)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(30, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        of4 = x\n",
    "        pal1_sources.append(of4)\n",
    "\n",
    "        # ===== Extras 层提取更深层特征 =====\n",
    "        for k in range(2):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of5 = x\n",
    "        pal1_sources.append(of5)\n",
    "\n",
    "        for k in range(2, 4):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of6 = x\n",
    "        pal1_sources.append(of6)\n",
    "\n",
    "        # ===== FPN特征金字塔自顶向下融合 =====\n",
    "        conv7 = F.relu(self.fpn_topdown[0](of6), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[1](conv7), inplace=True)\n",
    "        conv6 = F.relu(self._upsample_prod(x, self.fpn_latlayer[0](of5)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[2](conv6), inplace=True)\n",
    "        convfc7_2 = F.relu(self._upsample_prod(x, self.fpn_latlayer[1](of4)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[3](convfc7_2), inplace=True)\n",
    "        conv5 = F.relu(self._upsample_prod(x, self.fpn_latlayer[2](of3)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[4](conv5), inplace=True)\n",
    "        conv4 = F.relu(self._upsample_prod(x, self.fpn_latlayer[3](of2)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[5](conv4), inplace=True)\n",
    "        conv3 = F.relu(self._upsample_prod(x, self.fpn_latlayer[4](of1)), inplace=True)\n",
    "\n",
    "        # ===== 融合后通过FEM多尺度模块 =====\n",
    "        ef1 = self.L2Normef1(self.fpn_fem[0](conv3))\n",
    "        ef2 = self.L2Normef2(self.fpn_fem[1](conv4))\n",
    "        ef3 = self.L2Normef3(self.fpn_fem[2](conv5))\n",
    "        ef4 = self.fpn_fem[3](convfc7_2)\n",
    "        ef5 = self.fpn_fem[4](conv6)\n",
    "        ef6 = self.fpn_fem[5](conv7)\n",
    "\n",
    "        pal2_sources = (ef1, ef2, ef3, ef4, ef5, ef6)\n",
    "\n",
    "        # ===== PAL1 / PAL2 检测头输出特征转换 =====\n",
    "        for (x, l, c) in zip(pal1_sources, self.loc_pal1, self.conf_pal1):\n",
    "            loc_pal1.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal1.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        for (x, l, c) in zip(pal2_sources, self.loc_pal2, self.conf_pal2):\n",
    "            loc_pal2.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal2.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        # ===== 统一Flatten为检测头最终预测格式 =====\n",
    "        features_maps = []\n",
    "        for i in range(len(loc_pal1)):\n",
    "            feat = [loc_pal1[i].size(1), loc_pal1[i].size(2)]\n",
    "            features_maps.append(feat)\n",
    "\n",
    "        loc_pal1 = torch.cat([o.view(o.size(0), -1) for o in loc_pal1], 1)\n",
    "        conf_pal1 = torch.cat([o.view(o.size(0), -1) for o in conf_pal1], 1)\n",
    "        loc_pal2 = torch.cat([o.view(o.size(0), -1) for o in loc_pal2], 1)\n",
    "        conf_pal2 = torch.cat([o.view(o.size(0), -1) for o in conf_pal2], 1)\n",
    "\n",
    "        # ===== PriorBox 生成锚框 =====\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=1)\n",
    "        self.priors_pal1 = Variable(priorbox.forward(), volatile=True)\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=2)\n",
    "        self.priors_pal2 = Variable(priorbox.forward(), volatile=True)\n",
    "\n",
    "        # ===== 测试与训练两种输出逻辑分支 =====\n",
    "        if self.phase == 'test':\n",
    "            output = self.detect.forward(\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                self.softmax(conf_pal2.view(conf_pal2.size(0), -1, self.num_classes)),\n",
    "                self.priors_pal2.type(type(x.data))\n",
    "            )\n",
    "        else:\n",
    "            output = (\n",
    "                loc_pal1.view(loc_pal1.size(0), -1, 4),\n",
    "                conf_pal1.view(conf_pal1.size(0), -1, self.num_classes),\n",
    "                self.priors_pal1,\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                conf_pal2.view(conf_pal2.size(0), -1, self.num_classes),\n",
    "                self.priors_pal2\n",
    "            )\n",
    "\n",
    "        return output, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3cc38-cb90-4d99-b43d-e32af5131bce",
   "metadata": {},
   "source": [
    "# 训练阶段完整前向传播（增强与检测联合训练）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b00dc8-cfd5-450b-b365-e544fdfe1269",
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(self, x, x_light, I, I_light):\n",
    "        \"\"\"\n",
    "        x: 暗光图像（原图）\n",
    "        x_light: 亮光图像（伪标签）\n",
    "        I, I_light: Retinex分解得到的照度图（伪GT）\n",
    "        \"\"\"\n",
    "        size = x.size()[2:]\n",
    "        pal1_sources, pal2_sources = [], []\n",
    "        loc_pal1, conf_pal1 = [], []\n",
    "        loc_pal2, conf_pal2 = [], []\n",
    "\n",
    "        # ===== 亮图VGG特征提取（亮光增强分支） =====\n",
    "        for k in range(5):\n",
    "            x_light = self.vgg[k](x_light)\n",
    "\n",
    "        # ===== 暗图VGG特征提取（暗光增强分支） =====\n",
    "        for k in range(16):\n",
    "            x = self.vgg[k](x)\n",
    "            if k == 4:\n",
    "                x_dark = x  # conv4_3特征存储用于增强分支\n",
    "\n",
    "        # ===== 曝光增强解码器（第一轮反射重建） =====\n",
    "        R_dark = self.ref(x_dark)\n",
    "        R_light = self.ref(x_light)\n",
    "\n",
    "        # ===== 互换交叉增强，生成二次伪增强图 =====\n",
    "        x_dark_2 = (I * R_light).detach()\n",
    "        x_light_2 = (I_light * R_dark).detach()\n",
    "\n",
    "        for k in range(5):\n",
    "            x_light_2 = self.vgg[k](x_light_2)\n",
    "        for k in range(5):\n",
    "            x_dark_2 = self.vgg[k](x_dark_2)\n",
    "\n",
    "        # ===== 曝光增强解码器（二次反射重建） =====\n",
    "        R_dark_2 = self.ref(x_light_2)\n",
    "        R_light_2 = self.ref(x_dark_2)\n",
    "\n",
    "        # ===== KL蒸馏损失计算（互信息对齐） =====\n",
    "        x_light = x_light.flatten(start_dim=2).mean(dim=-1)\n",
    "        x_dark = x_dark.flatten(start_dim=2).mean(dim=-1)\n",
    "        x_light_2 = x_light_2.flatten(start_dim=2).mean(dim=-1)\n",
    "        x_dark_2 = x_dark_2.flatten(start_dim=2).mean(dim=-1)\n",
    "\n",
    "        loss_mutual = cfg.WEIGHT.MC * (\n",
    "            self.KL(x_light, x_dark) + self.KL(x_dark, x_light)\n",
    "            + self.KL(x_light_2, x_dark_2) + self.KL(x_dark_2, x_light_2)\n",
    "        )\n",
    "\n",
    "        # ===== 后续标准检测分支逻辑完全沿用PAL结构 =====\n",
    "\n",
    "        of1 = x\n",
    "        s = self.L2Normof1(of1)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(16, 23):\n",
    "            x = self.vgg[k](x)\n",
    "        of2 = x\n",
    "        s = self.L2Normof2(of2)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(23, 30):\n",
    "            x = self.vgg[k](x)\n",
    "        of3 = x\n",
    "        s = self.L2Normof3(of3)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(30, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        of4 = x\n",
    "        pal1_sources.append(of4)\n",
    "\n",
    "        for k in range(2):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of5 = x\n",
    "        pal1_sources.append(of5)\n",
    "        for k in range(2, 4):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of6 = x\n",
    "        pal1_sources.append(of6)\n",
    "\n",
    "        conv7 = F.relu(self.fpn_topdown[0](of6), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[1](conv7), inplace=True)\n",
    "        conv6 = F.relu(self._upsample_prod(x, self.fpn_latlayer[0](of5)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[2](conv6), inplace=True)\n",
    "        convfc7_2 = F.relu(self._upsample_prod(x, self.fpn_latlayer[1](of4)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[3](convfc7_2), inplace=True)\n",
    "        conv5 = F.relu(self._upsample_prod(x, self.fpn_latlayer[2](of3)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[4](conv5), inplace=True)\n",
    "        conv4 = F.relu(self._upsample_prod(x, self.fpn_latlayer[3](of2)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[5](conv4), inplace=True)\n",
    "        conv3 = F.relu(self._upsample_prod(x, self.fpn_latlayer[4](of1)), inplace=True)\n",
    "\n",
    "        ef1 = self.L2Normef1(self.fpn_fem[0](conv3))\n",
    "        ef2 = self.L2Normef2(self.fpn_fem[1](conv4))\n",
    "        ef3 = self.L2Normef3(self.fpn_fem[2](conv5))\n",
    "        ef4 = self.fpn_fem[3](convfc7_2)\n",
    "        ef5 = self.fpn_fem[4](conv6)\n",
    "        ef6 = self.fpn_fem[5](conv7)\n",
    "\n",
    "        pal2_sources = (ef1, ef2, ef3, ef4, ef5, ef6)\n",
    "\n",
    "        for (x, l, c) in zip(pal1_sources, self.loc_pal1, self.conf_pal1):\n",
    "            loc_pal1.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal1.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        for (x, l, c) in zip(pal2_sources, self.loc_pal2, self.conf_pal2):\n",
    "            loc_pal2.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal2.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        features_maps = []\n",
    "        for i in range(len(loc_pal1)):\n",
    "            feat = [loc_pal1[i].size(1), loc_pal1[i].size(2)]\n",
    "            features_maps.append(feat)\n",
    "\n",
    "        loc_pal1 = torch.cat([o.view(o.size(0), -1) for o in loc_pal1], 1)\n",
    "        conf_pal1 = torch.cat([o.view(o.size(0), -1) for o in conf_pal1], 1)\n",
    "        loc_pal2 = torch.cat([o.view(o.size(0), -1) for o in loc_pal2], 1)\n",
    "        conf_pal2 = torch.cat([o.view(o.size(0), -1) for o in conf_pal2], 1)\n",
    "\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=1)\n",
    "        self.priors_pal1 = Variable(priorbox.forward(), volatile=True)\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=2)\n",
    "        self.priors_pal2 = Variable(priorbox.forward(), volatile=True)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            output = self.detect.forward(\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                self.softmax(conf_pal2.view(conf_pal2.size(0), -1, self.num_classes)),\n",
    "                self.priors_pal2.type(type(x.data))\n",
    "            )\n",
    "        else:\n",
    "            output = (\n",
    "                loc_pal1.view(loc_pal1.size(0), -1, 4),\n",
    "                conf_pal1.view(loc_pal1.size(0), -1, self.num_classes),\n",
    "                self.priors_pal1,\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                conf_pal2.view(loc_pal2.size(0), -1, self.num_classes),\n",
    "                self.priors_pal2\n",
    "            )\n",
    "\n",
    "        return output, [R_dark, R_light, R_dark_2, R_light_2], loss_mutual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56990e-d022-401c-acbd-ca9c62d8a070",
   "metadata": {},
   "source": [
    "# 预训练模型权重加载函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef07aa-acd3-445d-aa76-acd80d795c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(self, base_file):\n",
    "        \"\"\"\n",
    "        从文件加载模型权重\n",
    "        \"\"\"\n",
    "        other, ext = os.path.splitext(base_file)\n",
    "        if ext == '.pkl' or '.pth':\n",
    "            print('Loading weights into state dict...')\n",
    "            mdata = torch.load(base_file, map_location=lambda storage, loc: storage)\n",
    "            epoch = 50  # 默认训练epoch初始化为50\n",
    "            self.load_state_dict(mdata)\n",
    "            print('Finished!')\n",
    "        else:\n",
    "            print('只支持 .pth 和 .pkl 格式权重文件')\n",
    "        return epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360d948-64cc-4ea6-ae5d-8b80761ae03c",
   "metadata": {},
   "source": [
    "# Xavier初始化（所有卷积层统一初始化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c32b6-69d5-4169-8d8d-80f391da57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def xavier(self, param):\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        \"\"\"\n",
    "        网络模块初始化权重\n",
    "        \"\"\"\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            self.xavier(m.weight.data)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "        if isinstance(m, nn.ConvTranspose2d):\n",
    "            self.xavier(m.weight.data)\n",
    "            if 'bias' in m.state_dict().keys():\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data[...] = 1\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf0c69-4625-4160-9f6c-745ea6a8929e",
   "metadata": {},
   "source": [
    "# 配置模块：基础网络层级配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00db959-11da-4734-8503-b0b065966fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_cfg = [\n",
    "    64, 64, 'M', \n",
    "    128, 128, 'M', \n",
    "    256, 256, 256, 'C', \n",
    "    512, 512, 512, 'M',\n",
    "    512, 512, 512, 'M'\n",
    "]\n",
    "\n",
    "extras_cfg = [256, 'S', 512, 128, 'S', 256]  # 扩展额外检测层\n",
    "fem_cfg = [256, 512, 512, 1024, 512, 256]    # 特征金字塔增强模块FEM配置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ca2f6-1d6f-4221-8b53-5b61e9b3a610",
   "metadata": {},
   "source": [
    "# FEM模块构造函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25214484-d1ac-4f65-9057-3e5729c25daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fem_module(cfg):\n",
    "    topdown_layers, lat_layers, fem_layers = [], [], []\n",
    "    topdown_layers += [nn.Conv2d(cfg[-1], cfg[-1], kernel_size=1)]\n",
    "    for k, v in enumerate(cfg):\n",
    "        fem_layers += [FEM(v)]\n",
    "        cur_channel = cfg[len(cfg) - 1 - k]\n",
    "        if len(cfg) - 1 - k > 0:\n",
    "            last_channel = cfg[len(cfg) - 2 - k]\n",
    "            topdown_layers += [nn.Conv2d(cur_channel, last_channel, kernel_size=1)]\n",
    "            lat_layers += [nn.Conv2d(last_channel, last_channel, kernel_size=1)]\n",
    "    return (topdown_layers, lat_layers, fem_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052bc17-9eb0-4ee0-bc5a-44810192bf06",
   "metadata": {},
   "source": [
    "#  VGG主干网络构造函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe2c36-1bde-4c5c-a938-98b46f526412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(cfg, i, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(2, 2)]\n",
    "        elif v == 'C':\n",
    "            layers += [nn.MaxPool2d(2, 2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, 3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    layers += [\n",
    "        nn.Conv2d(512, 1024, kernel_size=3, padding=3, dilation=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(1024, 1024, kernel_size=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a82e5-e7d9-4f09-9dc5-5d74798843f0",
   "metadata": {},
   "source": [
    "# Extras扩展检测头构造函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd01846-86fe-4ff9-b210-55d215673246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extras(cfg, i, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    flag = False\n",
    "    for k, v in enumerate(cfg):\n",
    "        if in_channels != 'S':\n",
    "            if v == 'S':\n",
    "                layers += [nn.Conv2d(in_channels, cfg[k + 1],\n",
    "                                     kernel_size=(1, 3)[flag], stride=2, padding=1)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]\n",
    "            flag = not flag\n",
    "        in_channels = v\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b61a4-a37a-4a5c-b434-ac885a2a66e5",
   "metadata": {},
   "source": [
    "# 多尺度检测头模块构造器（PAL1 / PAL2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc59f5-b8bf-4d8f-800d-f6da7f8e078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multibox(vgg, extra_layers, num_classes):\n",
    "    loc_layers, conf_layers = [], []\n",
    "    vgg_source = [14, 21, 28, -2]\n",
    "\n",
    "    for v in vgg_source:\n",
    "        loc_layers += [nn.Conv2d(vgg[v].out_channels, 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(vgg[v].out_channels, num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    for v in extra_layers[1::2]:\n",
    "        loc_layers += [nn.Conv2d(v.out_channels, 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(v.out_channels, num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    return (loc_layers, conf_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4377d6-157d-4c01-9db7-6ac912dd3aa4",
   "metadata": {},
   "source": [
    "# 完整模型构造函数（统一入口）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc72e32-babc-4e11-9ae7-61164d05fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net_dark(phase, num_classes=2):\n",
    "    base = vgg(vgg_cfg, 3)\n",
    "    extras = add_extras(extras_cfg, 1024)\n",
    "    head1 = multibox(base, extras, num_classes)\n",
    "    head2 = multibox(base, extras, num_classes)\n",
    "    fem = fem_module(fem_cfg)\n",
    "    return DSFD(phase, base, extras, fem, head1, head2, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb827dd2-c457-4180-af31-7b2eb918b270",
   "metadata": {},
   "source": [
    "# 蒸馏对齐KL散度损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9821e0-0abd-40d3-8201-2228715bdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillKL(nn.Module):\n",
    "    def __init__(self, T):\n",
    "        super(DistillKL, self).__init__()\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, y_s, y_t):\n",
    "        p_s = F.log_softmax(y_s / self.T, dim=1)\n",
    "        p_t = F.softmax(y_t / self.T, dim=1)\n",
    "        loss = F.kl_div(p_s, p_t, reduction='batchmean') * (self.T ** 2)\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin",
   "language": "python",
   "name": "lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
