{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ba34e81-7b1d-435e-beaf-adddd7681fe6",
   "metadata": {},
   "source": [
    "# Âü∫Êú¨Ê®°ÂùóÂØºÂÖ•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f39969-b94f-4c88-b258-cb6422618d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable, Function\n",
    "\n",
    "from layers import *  # DSFD‰∏≠‰ΩøÁî®ÁöÑÂ∑•ÂÖ∑Â±ÇÔºåÂ¶Ç L2Norm, PriorBox, Detect Á≠â\n",
    "from data.config import cfg  # ÈÖçÁΩÆÊñá‰ª∂ÔºåÂåÖÂê´Ê®°ÂûãÂèÇÊï∞„ÄÅËÆ≠ÁªÉÂèÇÊï∞Á≠â"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f62e90-3752-407c-bd8a-020184fabe94",
   "metadata": {},
   "source": [
    "# ÊèíÂÄºÊ®°Âùó"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839c5294-4a2f-46a2-84b2-f1120e521690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interpolate(nn.Module):\n",
    "    def __init__(self, scale_factor):\n",
    "        super(Interpolate, self).__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.interpolate(x, scale_factor=self.scale_factor, mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14936da-3265-4d2f-ba6c-8d55b9ac7ed5",
   "metadata": {},
   "source": [
    "# ÁâπÂæÅÂ¢ûÂº∫Ê®°Âùó (FEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ac31e8-0f6a-4762-b498-84af4533e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FEM(nn.Module):\n",
    "    \"\"\"\n",
    "    ËæìÂÖ•ÁâπÂæÅÈÄöÈÅìË¢´ÂùáÂåÄÂàíÂàÜÂà∞‰∏âË∑ØÂàÜÊîØÔºö\n",
    "      - ÂàÜÊîØ‰∏ÄÔºöÂçïÂ±ÇËÜ®ËÉÄÂç∑ÁßØ\n",
    "      - ÂàÜÊîØ‰∫åÔºö‰∏§Â±ÇËÜ®ËÉÄÂç∑ÁßØÂ†ÜÂè†\n",
    "      - ÂàÜÊîØ‰∏âÔºö‰∏âÂ±ÇËÜ®ËÉÄÂç∑ÁßØÂ†ÜÂè†\n",
    "    Â§öË∑ØÁâπÂæÅËûçÂêàÂ¢ûÂº∫ÁâπÂæÅÊèêÂèñËÉΩÂäõ\n",
    "    \"\"\"\n",
    "    def __init__(self, in_planes):\n",
    "        super(FEM, self).__init__()\n",
    "        inter_planes = in_planes // 3\n",
    "        inter_planes1 = in_planes - 2 * inter_planes\n",
    "\n",
    "        self.branch1 = nn.Conv2d(in_planes, inter_planes, kernel_size=3, padding=3, dilation=3)\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, inter_planes, kernel_size=3, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_planes, inter_planes, kernel_size=3, padding=3, dilation=3)\n",
    "        )\n",
    "\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Conv2d(in_planes, inter_planes1, kernel_size=3, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_planes1, inter_planes1, kernel_size=3, padding=3, dilation=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(inter_planes1, inter_planes1, kernel_size=3, padding=3, dilation=3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.branch1(x)\n",
    "        x2 = self.branch2(x)\n",
    "        x3 = self.branch3(x)\n",
    "        out = torch.cat((x1, x2, x3), dim=1)\n",
    "        return F.relu(out, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c546fc9a-4f06-480a-96dc-28b2c6ef9f58",
   "metadata": {},
   "source": [
    "# Êï¥‰Ωì DSFD ‰∏ª‰ΩìÊû∂ÊûÑ (ÂåÖÂê´Â¢ûÂº∫+Ê£ÄÊµãËÅîÂêà)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f3c9ff-fae6-4f84-a0c6-0d4af75bf512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSFD(nn.Module):\n",
    "    \"\"\"\n",
    "    DSFD‰∏ªÂπ≤ÁΩëÁªúÔºö\n",
    "    - Âü∫‰∫éVGGÁöÑÂü∫Á°ÄÁâπÂæÅÊèêÂèñÂô®\n",
    "    - ‰∏§Èò∂ÊÆµÔºàPAL1 / PAL2ÔºâÊ£ÄÊµãÂ§¥\n",
    "    - ÁâπÂæÅÈáëÂ≠óÂ°îÊ®°Âùó (FPN + FEM)\n",
    "    - ÂèçÂ∞ÑÂ¢ûÂº∫Ê®°Âùó (Reflectance Decoder)\n",
    "    - Ëí∏È¶èÂØπÈΩêÊ®°Âùó (KL Divergence)\n",
    "    \"\"\"\n",
    "    def __init__(self, phase, base, extras, fem, head1, head2, num_classes):\n",
    "        super(DSFD, self).__init__()\n",
    "        self.phase = phase  # ËÆ≠ÁªÉ or ÊµãËØï\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # VGG‰∏ªÂπ≤ÁΩëÁªú\n",
    "        self.vgg = nn.ModuleList(base)\n",
    "\n",
    "        # Â§öÂ±ÇÁâπÂæÅÂΩí‰∏ÄÂåñ (L2NormÔºåÈò≤Ê≠¢Êï∞ÂÄºÈúáËç°)\n",
    "        self.L2Normof1 = L2Norm(256, 10)\n",
    "        self.L2Normof2 = L2Norm(512, 8)\n",
    "        self.L2Normof3 = L2Norm(512, 5)\n",
    "\n",
    "        # Êâ©Â±ïÈ¢ùÂ§ñÂ±ÇÔºàÊõ¥Ê∑±Â±ÇÁâπÂæÅÊèêÂèñÔºâ\n",
    "        self.extras = nn.ModuleList(extras)\n",
    "\n",
    "        # FPNÈ°∂Âêë‰∏ã(top-down)ËûçÂêà + ‰æßÂêëËøûÊé•(lateral) + FEMÊ®°Âùó\n",
    "        self.fpn_topdown = nn.ModuleList(fem[0])\n",
    "        self.fpn_latlayer = nn.ModuleList(fem[1])\n",
    "        self.fpn_fem = nn.ModuleList(fem[2])\n",
    "\n",
    "        # ËûçÂêàÂêéÁöÑÁâπÂæÅÂõæÂÜçÊ¨°L2ÂΩí‰∏ÄÂåñ\n",
    "        self.L2Normef1 = L2Norm(256, 10)\n",
    "        self.L2Normef2 = L2Norm(512, 8)\n",
    "        self.L2Normef3 = L2Norm(512, 5)\n",
    "\n",
    "        # ‰∏§Èò∂ÊÆµÊ£ÄÊµãÂàÜÊîØÔºàPAL1„ÄÅPAL2Ôºâ\n",
    "        self.loc_pal1 = nn.ModuleList(head1[0])\n",
    "        self.conf_pal1 = nn.ModuleList(head1[1])\n",
    "        self.loc_pal2 = nn.ModuleList(head2[0])\n",
    "        self.conf_pal2 = nn.ModuleList(head2[1])\n",
    "\n",
    "        # üåü ÂèçÂ∞ÑÂ¢ûÂº∫Ëß£Á†ÅÂàÜÊîØ (Reflectance Decoder)\n",
    "        self.ref = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Interpolate(2),  # ‰∏äÈááÊ†∑ÊîæÂ§ß‰∏§ÂÄç\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()     # ËæìÂá∫ËåÉÂõ¥ÈôêÂà∂Âú®[0,1]\n",
    "        )\n",
    "\n",
    "        # üåü Ëí∏È¶èÊçüÂ§±Ê®°Âùó (Áî®‰∫éÂ¢ûÂº∫ÁâπÂæÅÂØπÈΩê)\n",
    "        self.KL = DistillKL(T=4.0)\n",
    "\n",
    "        # ÊµãËØïÈò∂ÊÆµÂä†ÂÖ•softmaxÂàÜÁ±ªÂô®ÂíåÊúÄÁªàDetectËß£Á†ÅÂô®\n",
    "        if self.phase == 'test':\n",
    "            self.softmax = nn.Softmax(dim=-1)\n",
    "            self.detect = Detect(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbb5d71-5a53-459a-9f75-8aa7615b6320",
   "metadata": {},
   "source": [
    "# Ëá™ÂÆö‰πâÁâπÂæÅ‰∏äÈááÊ†∑Âπ∂‰πòÊ≥ïËûçÂêàÂáΩÊï∞ÔºàFPNÁî®Ôºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cac4cd-310e-4800-9e63-d11079863572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _upsample_prod(self, x, y):\n",
    "        _, _, H, W = y.size()\n",
    "        return F.upsample(x, size=(H, W), mode='bilinear') * y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce56492-509a-4745-a5c4-95e846cd966d",
   "metadata": {},
   "source": [
    "# Âè™Áî®‰∫éÂ¢ûÂº∫Ëß£Á†ÅÔºàÁ∫ØÂèçÂ∞ÑÂàÜÊîØÊé®ÁêÜÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1d1029-59af-4671-af39-e47cffbb719e",
   "metadata": {},
   "outputs": [],
   "source": [
    " def enh_forward(self, x):\n",
    "        x = x[:1]  # ‰ªÖÂ§ÑÁêÜÁ¨¨‰∏ÄÂº†ÂõæÁâáÔºåÈÄöÂ∏∏ËÆ≠ÁªÉÂçïÂº†Â¢ûÂº∫\n",
    "        for k in range(5):\n",
    "            x = self.vgg[k](x)\n",
    "        R = self.ref(x)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb453957-65c5-49e4-96ac-f0be0f269b2f",
   "metadata": {},
   "source": [
    "# ÂÆåÊï¥ÊµãËØïÂâçÂêëÊé®ÁêÜ (Ê£ÄÊµã‰∏éÂ¢ûÂº∫ËÅîÂêàËæìÂá∫)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f9366-8f9a-4347-8db8-28d7b76f31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def test_forward(self, x):\n",
    "        size = x.size()[2:]  # ËæìÂÖ•ÂõæÂÉèÂ∞∫ÂØ∏\n",
    "        pal1_sources, pal2_sources = [], []  # ‰∏§Èò∂ÊÆµÁâπÂæÅÁºìÂ≠ò\n",
    "        loc_pal1, conf_pal1 = [], []         # PAL1È¢ÑÊµãËæìÂá∫\n",
    "        loc_pal2, conf_pal2 = [], []         # PAL2È¢ÑÊµãËæìÂá∫\n",
    "\n",
    "        # ===== VGG ÁâπÂæÅÊäΩÂèñÈò∂ÊÆµ =====\n",
    "        for k in range(16):\n",
    "            x = self.vgg[k](x)\n",
    "            if k == 4:  # conv4_3ÁâπÂæÅÊèêÂâçÊèêÂèñÔºåÁî®‰∫éÂ¢ûÂº∫Ê®°Âùó\n",
    "                x_ = x\n",
    "        R = self.ref(x_[0:1])  # Â¢ûÂº∫Ê®°ÂùóÂèçÂ∞ÑËß£Á†ÅËæìÂá∫\n",
    "\n",
    "        of1 = x\n",
    "        s = self.L2Normof1(of1)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(16, 23):\n",
    "            x = self.vgg[k](x)\n",
    "        of2 = x\n",
    "        s = self.L2Normof2(of2)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(23, 30):\n",
    "            x = self.vgg[k](x)\n",
    "        of3 = x\n",
    "        s = self.L2Normof3(of3)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(30, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        of4 = x\n",
    "        pal1_sources.append(of4)\n",
    "\n",
    "        # ===== Extras Â±ÇÊèêÂèñÊõ¥Ê∑±Â±ÇÁâπÂæÅ =====\n",
    "        for k in range(2):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of5 = x\n",
    "        pal1_sources.append(of5)\n",
    "\n",
    "        for k in range(2, 4):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of6 = x\n",
    "        pal1_sources.append(of6)\n",
    "\n",
    "        # ===== FPNÁâπÂæÅÈáëÂ≠óÂ°îËá™È°∂Âêë‰∏ãËûçÂêà =====\n",
    "        conv7 = F.relu(self.fpn_topdown[0](of6), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[1](conv7), inplace=True)\n",
    "        conv6 = F.relu(self._upsample_prod(x, self.fpn_latlayer[0](of5)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[2](conv6), inplace=True)\n",
    "        convfc7_2 = F.relu(self._upsample_prod(x, self.fpn_latlayer[1](of4)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[3](convfc7_2), inplace=True)\n",
    "        conv5 = F.relu(self._upsample_prod(x, self.fpn_latlayer[2](of3)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[4](conv5), inplace=True)\n",
    "        conv4 = F.relu(self._upsample_prod(x, self.fpn_latlayer[3](of2)), inplace=True)\n",
    "\n",
    "        x = F.relu(self.fpn_topdown[5](conv4), inplace=True)\n",
    "        conv3 = F.relu(self._upsample_prod(x, self.fpn_latlayer[4](of1)), inplace=True)\n",
    "\n",
    "        # ===== ËûçÂêàÂêéÈÄöËøáFEMÂ§öÂ∞∫Â∫¶Ê®°Âùó =====\n",
    "        ef1 = self.L2Normef1(self.fpn_fem[0](conv3))\n",
    "        ef2 = self.L2Normef2(self.fpn_fem[1](conv4))\n",
    "        ef3 = self.L2Normef3(self.fpn_fem[2](conv5))\n",
    "        ef4 = self.fpn_fem[3](convfc7_2)\n",
    "        ef5 = self.fpn_fem[4](conv6)\n",
    "        ef6 = self.fpn_fem[5](conv7)\n",
    "\n",
    "        pal2_sources = (ef1, ef2, ef3, ef4, ef5, ef6)\n",
    "\n",
    "        # ===== PAL1 / PAL2 Ê£ÄÊµãÂ§¥ËæìÂá∫ÁâπÂæÅËΩ¨Êç¢ =====\n",
    "        for (x, l, c) in zip(pal1_sources, self.loc_pal1, self.conf_pal1):\n",
    "            loc_pal1.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal1.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        for (x, l, c) in zip(pal2_sources, self.loc_pal2, self.conf_pal2):\n",
    "            loc_pal2.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal2.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        # ===== Áªü‰∏ÄFlatten‰∏∫Ê£ÄÊµãÂ§¥ÊúÄÁªàÈ¢ÑÊµãÊ†ºÂºè =====\n",
    "        features_maps = []\n",
    "        for i in range(len(loc_pal1)):\n",
    "            feat = [loc_pal1[i].size(1), loc_pal1[i].size(2)]\n",
    "            features_maps.append(feat)\n",
    "\n",
    "        loc_pal1 = torch.cat([o.view(o.size(0), -1) for o in loc_pal1], 1)\n",
    "        conf_pal1 = torch.cat([o.view(o.size(0), -1) for o in conf_pal1], 1)\n",
    "        loc_pal2 = torch.cat([o.view(o.size(0), -1) for o in loc_pal2], 1)\n",
    "        conf_pal2 = torch.cat([o.view(o.size(0), -1) for o in conf_pal2], 1)\n",
    "\n",
    "        # ===== PriorBox ÁîüÊàêÈîöÊ°Ü =====\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=1)\n",
    "        self.priors_pal1 = Variable(priorbox.forward(), volatile=True)\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=2)\n",
    "        self.priors_pal2 = Variable(priorbox.forward(), volatile=True)\n",
    "\n",
    "        # ===== ÊµãËØï‰∏éËÆ≠ÁªÉ‰∏§ÁßçËæìÂá∫ÈÄªËæëÂàÜÊîØ =====\n",
    "        if self.phase == 'test':\n",
    "            output = self.detect.forward(\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                self.softmax(conf_pal2.view(conf_pal2.size(0), -1, self.num_classes)),\n",
    "                self.priors_pal2.type(type(x.data))\n",
    "            )\n",
    "        else:\n",
    "            output = (\n",
    "                loc_pal1.view(loc_pal1.size(0), -1, 4),\n",
    "                conf_pal1.view(conf_pal1.size(0), -1, self.num_classes),\n",
    "                self.priors_pal1,\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                conf_pal2.view(conf_pal2.size(0), -1, self.num_classes),\n",
    "                self.priors_pal2\n",
    "            )\n",
    "\n",
    "        return output, R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a3cc38-cb90-4d99-b43d-e32af5131bce",
   "metadata": {},
   "source": [
    "# ËÆ≠ÁªÉÈò∂ÊÆµÂÆåÊï¥ÂâçÂêë‰º†Êí≠ÔºàÂ¢ûÂº∫‰∏éÊ£ÄÊµãËÅîÂêàËÆ≠ÁªÉÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b00dc8-cfd5-450b-b365-e544fdfe1269",
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(self, x, x_light, I, I_light):\n",
    "        \"\"\"\n",
    "        x: ÊöóÂÖâÂõæÂÉèÔºàÂéüÂõæÔºâ\n",
    "        x_light: ‰∫ÆÂÖâÂõæÂÉèÔºà‰º™Ê†áÁ≠æÔºâ\n",
    "        I, I_light: RetinexÂàÜËß£ÂæóÂà∞ÁöÑÁÖßÂ∫¶ÂõæÔºà‰º™GTÔºâ\n",
    "        \"\"\"\n",
    "        size = x.size()[2:]\n",
    "        pal1_sources, pal2_sources = [], []\n",
    "        loc_pal1, conf_pal1 = [], []\n",
    "        loc_pal2, conf_pal2 = [], []\n",
    "\n",
    "        # ===== ‰∫ÆÂõæVGGÁâπÂæÅÊèêÂèñÔºà‰∫ÆÂÖâÂ¢ûÂº∫ÂàÜÊîØÔºâ =====\n",
    "        for k in range(5):\n",
    "            x_light = self.vgg[k](x_light)\n",
    "\n",
    "        # ===== ÊöóÂõæVGGÁâπÂæÅÊèêÂèñÔºàÊöóÂÖâÂ¢ûÂº∫ÂàÜÊîØÔºâ =====\n",
    "        for k in range(16):\n",
    "            x = self.vgg[k](x)\n",
    "            if k == 4:\n",
    "                x_dark = x  # conv4_3ÁâπÂæÅÂ≠òÂÇ®Áî®‰∫éÂ¢ûÂº∫ÂàÜÊîØ\n",
    "\n",
    "        # ===== ÊõùÂÖâÂ¢ûÂº∫Ëß£Á†ÅÂô®ÔºàÁ¨¨‰∏ÄËΩÆÂèçÂ∞ÑÈáçÂª∫Ôºâ =====\n",
    "        R_dark = self.ref(x_dark)\n",
    "        R_light = self.ref(x_light)\n",
    "\n",
    "        # ===== ‰∫íÊç¢‰∫§ÂèâÂ¢ûÂº∫ÔºåÁîüÊàê‰∫åÊ¨°‰º™Â¢ûÂº∫Âõæ =====\n",
    "        x_dark_2 = (I * R_light).detach()\n",
    "        x_light_2 = (I_light * R_dark).detach()\n",
    "\n",
    "        for k in range(5):\n",
    "            x_light_2 = self.vgg[k](x_light_2)\n",
    "        for k in range(5):\n",
    "            x_dark_2 = self.vgg[k](x_dark_2)\n",
    "\n",
    "        # ===== ÊõùÂÖâÂ¢ûÂº∫Ëß£Á†ÅÂô®Ôºà‰∫åÊ¨°ÂèçÂ∞ÑÈáçÂª∫Ôºâ =====\n",
    "        R_dark_2 = self.ref(x_light_2)\n",
    "        R_light_2 = self.ref(x_dark_2)\n",
    "\n",
    "        # ===== KLËí∏È¶èÊçüÂ§±ËÆ°ÁÆóÔºà‰∫í‰ø°ÊÅØÂØπÈΩêÔºâ =====\n",
    "        x_light = x_light.flatten(start_dim=2).mean(dim=-1)\n",
    "        x_dark = x_dark.flatten(start_dim=2).mean(dim=-1)\n",
    "        x_light_2 = x_light_2.flatten(start_dim=2).mean(dim=-1)\n",
    "        x_dark_2 = x_dark_2.flatten(start_dim=2).mean(dim=-1)\n",
    "\n",
    "        loss_mutual = cfg.WEIGHT.MC * (\n",
    "            self.KL(x_light, x_dark) + self.KL(x_dark, x_light)\n",
    "            + self.KL(x_light_2, x_dark_2) + self.KL(x_dark_2, x_light_2)\n",
    "        )\n",
    "\n",
    "        # ===== ÂêéÁª≠Ê†áÂáÜÊ£ÄÊµãÂàÜÊîØÈÄªËæëÂÆåÂÖ®Ê≤øÁî®PALÁªìÊûÑ =====\n",
    "\n",
    "        of1 = x\n",
    "        s = self.L2Normof1(of1)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(16, 23):\n",
    "            x = self.vgg[k](x)\n",
    "        of2 = x\n",
    "        s = self.L2Normof2(of2)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(23, 30):\n",
    "            x = self.vgg[k](x)\n",
    "        of3 = x\n",
    "        s = self.L2Normof3(of3)\n",
    "        pal1_sources.append(s)\n",
    "\n",
    "        for k in range(30, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "        of4 = x\n",
    "        pal1_sources.append(of4)\n",
    "\n",
    "        for k in range(2):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of5 = x\n",
    "        pal1_sources.append(of5)\n",
    "        for k in range(2, 4):\n",
    "            x = F.relu(self.extras[k](x), inplace=True)\n",
    "        of6 = x\n",
    "        pal1_sources.append(of6)\n",
    "\n",
    "        conv7 = F.relu(self.fpn_topdown[0](of6), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[1](conv7), inplace=True)\n",
    "        conv6 = F.relu(self._upsample_prod(x, self.fpn_latlayer[0](of5)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[2](conv6), inplace=True)\n",
    "        convfc7_2 = F.relu(self._upsample_prod(x, self.fpn_latlayer[1](of4)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[3](convfc7_2), inplace=True)\n",
    "        conv5 = F.relu(self._upsample_prod(x, self.fpn_latlayer[2](of3)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[4](conv5), inplace=True)\n",
    "        conv4 = F.relu(self._upsample_prod(x, self.fpn_latlayer[3](of2)), inplace=True)\n",
    "        x = F.relu(self.fpn_topdown[5](conv4), inplace=True)\n",
    "        conv3 = F.relu(self._upsample_prod(x, self.fpn_latlayer[4](of1)), inplace=True)\n",
    "\n",
    "        ef1 = self.L2Normef1(self.fpn_fem[0](conv3))\n",
    "        ef2 = self.L2Normef2(self.fpn_fem[1](conv4))\n",
    "        ef3 = self.L2Normef3(self.fpn_fem[2](conv5))\n",
    "        ef4 = self.fpn_fem[3](convfc7_2)\n",
    "        ef5 = self.fpn_fem[4](conv6)\n",
    "        ef6 = self.fpn_fem[5](conv7)\n",
    "\n",
    "        pal2_sources = (ef1, ef2, ef3, ef4, ef5, ef6)\n",
    "\n",
    "        for (x, l, c) in zip(pal1_sources, self.loc_pal1, self.conf_pal1):\n",
    "            loc_pal1.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal1.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        for (x, l, c) in zip(pal2_sources, self.loc_pal2, self.conf_pal2):\n",
    "            loc_pal2.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf_pal2.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        features_maps = []\n",
    "        for i in range(len(loc_pal1)):\n",
    "            feat = [loc_pal1[i].size(1), loc_pal1[i].size(2)]\n",
    "            features_maps.append(feat)\n",
    "\n",
    "        loc_pal1 = torch.cat([o.view(o.size(0), -1) for o in loc_pal1], 1)\n",
    "        conf_pal1 = torch.cat([o.view(o.size(0), -1) for o in conf_pal1], 1)\n",
    "        loc_pal2 = torch.cat([o.view(o.size(0), -1) for o in loc_pal2], 1)\n",
    "        conf_pal2 = torch.cat([o.view(o.size(0), -1) for o in conf_pal2], 1)\n",
    "\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=1)\n",
    "        self.priors_pal1 = Variable(priorbox.forward(), volatile=True)\n",
    "        priorbox = PriorBox(size, features_maps, cfg, pal=2)\n",
    "        self.priors_pal2 = Variable(priorbox.forward(), volatile=True)\n",
    "\n",
    "        if self.phase == 'test':\n",
    "            output = self.detect.forward(\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                self.softmax(conf_pal2.view(conf_pal2.size(0), -1, self.num_classes)),\n",
    "                self.priors_pal2.type(type(x.data))\n",
    "            )\n",
    "        else:\n",
    "            output = (\n",
    "                loc_pal1.view(loc_pal1.size(0), -1, 4),\n",
    "                conf_pal1.view(loc_pal1.size(0), -1, self.num_classes),\n",
    "                self.priors_pal1,\n",
    "                loc_pal2.view(loc_pal2.size(0), -1, 4),\n",
    "                conf_pal2.view(loc_pal2.size(0), -1, self.num_classes),\n",
    "                self.priors_pal2\n",
    "            )\n",
    "\n",
    "        return output, [R_dark, R_light, R_dark_2, R_light_2], loss_mutual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae56990e-d022-401c-acbd-ca9c62d8a070",
   "metadata": {},
   "source": [
    "# È¢ÑËÆ≠ÁªÉÊ®°ÂûãÊùÉÈáçÂä†ËΩΩÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ef07aa-acd3-445d-aa76-acd80d795c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weights(self, base_file):\n",
    "        \"\"\"\n",
    "        ‰ªéÊñá‰ª∂Âä†ËΩΩÊ®°ÂûãÊùÉÈáç\n",
    "        \"\"\"\n",
    "        other, ext = os.path.splitext(base_file)\n",
    "        if ext == '.pkl' or '.pth':\n",
    "            print('Loading weights into state dict...')\n",
    "            mdata = torch.load(base_file, map_location=lambda storage, loc: storage)\n",
    "            epoch = 50  # ÈªòËÆ§ËÆ≠ÁªÉepochÂàùÂßãÂåñ‰∏∫50\n",
    "            self.load_state_dict(mdata)\n",
    "            print('Finished!')\n",
    "        else:\n",
    "            print('Âè™ÊîØÊåÅ .pth Âíå .pkl Ê†ºÂºèÊùÉÈáçÊñá‰ª∂')\n",
    "        return epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1360d948-64cc-4ea6-ae5d-8b80761ae03c",
   "metadata": {},
   "source": [
    "# XavierÂàùÂßãÂåñÔºàÊâÄÊúâÂç∑ÁßØÂ±ÇÁªü‰∏ÄÂàùÂßãÂåñÔºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041c32b6-69d5-4169-8d8d-80f391da57ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def xavier(self, param):\n",
    "        init.xavier_uniform_(param)\n",
    "\n",
    "    def weights_init(self, m):\n",
    "        \"\"\"\n",
    "        ÁΩëÁªúÊ®°ÂùóÂàùÂßãÂåñÊùÉÈáç\n",
    "        \"\"\"\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            self.xavier(m.weight.data)\n",
    "            m.bias.data.zero_()\n",
    "\n",
    "        if isinstance(m, nn.ConvTranspose2d):\n",
    "            self.xavier(m.weight.data)\n",
    "            if 'bias' in m.state_dict().keys():\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        if isinstance(m, nn.BatchNorm2d):\n",
    "            m.weight.data[...] = 1\n",
    "            m.bias.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf0c69-4625-4160-9f6c-745ea6a8929e",
   "metadata": {},
   "source": [
    "# ÈÖçÁΩÆÊ®°ÂùóÔºöÂü∫Á°ÄÁΩëÁªúÂ±ÇÁ∫ßÈÖçÁΩÆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00db959-11da-4734-8503-b0b065966fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_cfg = [\n",
    "    64, 64, 'M', \n",
    "    128, 128, 'M', \n",
    "    256, 256, 256, 'C', \n",
    "    512, 512, 512, 'M',\n",
    "    512, 512, 512, 'M'\n",
    "]\n",
    "\n",
    "extras_cfg = [256, 'S', 512, 128, 'S', 256]  # Êâ©Â±ïÈ¢ùÂ§ñÊ£ÄÊµãÂ±Ç\n",
    "fem_cfg = [256, 512, 512, 1024, 512, 256]    # ÁâπÂæÅÈáëÂ≠óÂ°îÂ¢ûÂº∫Ê®°ÂùóFEMÈÖçÁΩÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ca2f6-1d6f-4221-8b53-5b61e9b3a610",
   "metadata": {},
   "source": [
    "# FEMÊ®°ÂùóÊûÑÈÄ†ÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25214484-d1ac-4f65-9057-3e5729c25daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fem_module(cfg):\n",
    "    topdown_layers, lat_layers, fem_layers = [], [], []\n",
    "    topdown_layers += [nn.Conv2d(cfg[-1], cfg[-1], kernel_size=1)]\n",
    "    for k, v in enumerate(cfg):\n",
    "        fem_layers += [FEM(v)]\n",
    "        cur_channel = cfg[len(cfg) - 1 - k]\n",
    "        if len(cfg) - 1 - k > 0:\n",
    "            last_channel = cfg[len(cfg) - 2 - k]\n",
    "            topdown_layers += [nn.Conv2d(cur_channel, last_channel, kernel_size=1)]\n",
    "            lat_layers += [nn.Conv2d(last_channel, last_channel, kernel_size=1)]\n",
    "    return (topdown_layers, lat_layers, fem_layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e052bc17-9eb0-4ee0-bc5a-44810192bf06",
   "metadata": {},
   "source": [
    "#  VGG‰∏ªÂπ≤ÁΩëÁªúÊûÑÈÄ†ÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe2c36-1bde-4c5c-a938-98b46f526412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(cfg, i, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(2, 2)]\n",
    "        elif v == 'C':\n",
    "            layers += [nn.MaxPool2d(2, 2, ceil_mode=True)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, 3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    layers += [\n",
    "        nn.Conv2d(512, 1024, kernel_size=3, padding=3, dilation=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(1024, 1024, kernel_size=1),\n",
    "        nn.ReLU(inplace=True)\n",
    "    ]\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a82e5-e7d9-4f09-9dc5-5d74798843f0",
   "metadata": {},
   "source": [
    "# ExtrasÊâ©Â±ïÊ£ÄÊµãÂ§¥ÊûÑÈÄ†ÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd01846-86fe-4ff9-b210-55d215673246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_extras(cfg, i, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = i\n",
    "    flag = False\n",
    "    for k, v in enumerate(cfg):\n",
    "        if in_channels != 'S':\n",
    "            if v == 'S':\n",
    "                layers += [nn.Conv2d(in_channels, cfg[k + 1],\n",
    "                                     kernel_size=(1, 3)[flag], stride=2, padding=1)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]\n",
    "            flag = not flag\n",
    "        in_channels = v\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39b61a4-a37a-4a5c-b434-ac885a2a66e5",
   "metadata": {},
   "source": [
    "# Â§öÂ∞∫Â∫¶Ê£ÄÊµãÂ§¥Ê®°ÂùóÊûÑÈÄ†Âô®ÔºàPAL1 / PAL2Ôºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc59f5-b8bf-4d8f-800d-f6da7f8e078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multibox(vgg, extra_layers, num_classes):\n",
    "    loc_layers, conf_layers = [], []\n",
    "    vgg_source = [14, 21, 28, -2]\n",
    "\n",
    "    for v in vgg_source:\n",
    "        loc_layers += [nn.Conv2d(vgg[v].out_channels, 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(vgg[v].out_channels, num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    for v in extra_layers[1::2]:\n",
    "        loc_layers += [nn.Conv2d(v.out_channels, 4, kernel_size=3, padding=1)]\n",
    "        conf_layers += [nn.Conv2d(v.out_channels, num_classes, kernel_size=3, padding=1)]\n",
    "\n",
    "    return (loc_layers, conf_layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4377d6-157d-4c01-9db7-6ac912dd3aa4",
   "metadata": {},
   "source": [
    "# ÂÆåÊï¥Ê®°ÂûãÊûÑÈÄ†ÂáΩÊï∞ÔºàÁªü‰∏ÄÂÖ•Âè£Ôºâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc72e32-babc-4e11-9ae7-61164d05fc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net_dark(phase, num_classes=2):\n",
    "    base = vgg(vgg_cfg, 3)\n",
    "    extras = add_extras(extras_cfg, 1024)\n",
    "    head1 = multibox(base, extras, num_classes)\n",
    "    head2 = multibox(base, extras, num_classes)\n",
    "    fem = fem_module(fem_cfg)\n",
    "    return DSFD(phase, base, extras, fem, head1, head2, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb827dd2-c457-4180-af31-7b2eb918b270",
   "metadata": {},
   "source": [
    "# Ëí∏È¶èÂØπÈΩêKLÊï£Â∫¶ÊçüÂ§±ÂáΩÊï∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9821e0-0abd-40d3-8201-2228715bdc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillKL(nn.Module):\n",
    "    def __init__(self, T):\n",
    "        super(DistillKL, self).__init__()\n",
    "        self.T = T\n",
    "\n",
    "    def forward(self, y_s, y_t):\n",
    "        p_s = F.log_softmax(y_s / self.T, dim=1)\n",
    "        p_t = F.softmax(y_t / self.T, dim=1)\n",
    "        loss = F.kl_div(p_s, p_t, reduction='batchmean') * (self.T ** 2)\n",
    "        return loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin",
   "language": "python",
   "name": "lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
