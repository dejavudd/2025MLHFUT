{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4690c87a-eb9f-48b9-9247-f70431bfb5b9",
   "metadata": {},
   "source": [
    "###   本模块在 DAI-Net 项目中扮演了图像增强的核心角色，旨在提升低光照图像的质量，为目标检测任务提供更清晰的输入数据。包含了 DecomNet、RetinexNet、ZeroDCE 和 Enhancer 等模块，通过深度学习和 Retinex 理论实现图像分解与增强，具体作用如下：它首先通过 ZeroDCE或 RetinexNet将图像分解为反射率和光照分量，随后，Enhancer 类根据参数选择合适的增强方法，确保灵活性和兼容性；最终，增强后的图像被输入到目标检测模型中，显著改善夜间或低光照场景下的检测性能，从而提升整个系统在日夜转换场景下的鲁棒性和准确性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f05df-730a-4f5a-bfd3-2602fa0393bb",
   "metadata": {},
   "source": [
    "## 1.导入所需模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fa010-61b6-49bb-9fc4-d5bda1220840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32336e-7aaf-4e75-9306-83a8d52888fb",
   "metadata": {},
   "source": [
    "### 2.原项目中基于 PyTorch 的神经网络模块，通过卷积层和 ReLU 激活函数实现低光照图像的分解，将输入图像分解为反射率（R）和光照（L）两个部分，用于图像增强任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ffdeda02-e20a-40fc-9015-6e0a24643efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecomNet(nn.Module):\n",
    "    def __init__(self, channel=64, kernel_size=3):\n",
    "        super(DecomNet, self).__init__()\n",
    "        # Shallow feature extraction\n",
    "        self.net1_conv0 = nn.Conv2d(4, channel, kernel_size * 3,\n",
    "                                    padding=4, padding_mode='replicate')\n",
    "        # Activated layers!\n",
    "        self.net1_convs = nn.Sequential(nn.Conv2d(channel, channel, kernel_size,\n",
    "                                                  padding=1, padding_mode='replicate'),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(channel, channel, kernel_size,\n",
    "                                                  padding=1, padding_mode='replicate'),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(channel, channel, kernel_size,\n",
    "                                                  padding=1, padding_mode='replicate'),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(channel, channel, kernel_size,\n",
    "                                                  padding=1, padding_mode='replicate'),\n",
    "                                        nn.ReLU(),\n",
    "                                        nn.Conv2d(channel, channel, kernel_size,\n",
    "                                                  padding=1, padding_mode='replicate'),\n",
    "                                        nn.ReLU())\n",
    "        # Final recon layer\n",
    "        self.net1_recon = nn.Conv2d(channel, 4, kernel_size,\n",
    "                                    padding=1, padding_mode='replicate')\n",
    "\n",
    "    def forward(self, input_im):\n",
    "        input_max = torch.max(input_im, dim=1, keepdim=True)[0]\n",
    "        input_img = torch.cat((input_max, input_im), dim=1)\n",
    "        feats0 = self.net1_conv0(input_img)\n",
    "        featss = self.net1_convs(feats0)\n",
    "        outs = self.net1_recon(featss)\n",
    "        R = torch.sigmoid(outs[:, 0:3, :, :])\n",
    "        L = torch.sigmoid(outs[:, 3:4, :, :])\n",
    "        return R, L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32ae31c-68a9-4089-8576-a5cbabee2147",
   "metadata": {},
   "source": [
    "### 3.基于 PyTorch 的模块，旨在为图像增强任务提供灵活的选择，通过参数决定使用 ZeroDCE 或 RetinexNet 进行处理，并在 forward 方法中根据选择调用相应的增强器，返回增强后的图像及可能的附加输出，以适应不同场景的增强需求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c727bc-465c-49e9-bab6-e5db61ca0d03",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# This Retinex Decom Net is frozen during training of DAI-Net\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mEnhancer\u001b[39;00m(\u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, use_zerodce\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "# This Retinex Decom Net is frozen during training of DAI-Net\n",
    "class Enhancer(nn.Module):\n",
    "    def __init__(self, use_zerodce=True):\n",
    "        super().__init__()\n",
    "        self.use_zerodce = use_zerodce\n",
    "        if use_zerodce:\n",
    "            self.enhancer = ZeroDCE()\n",
    "        else:\n",
    "            self.enhancer = RetinexNet()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_zerodce:\n",
    "            enhanced, _ = self.enhancer(x)\n",
    "            return enhanced, None  # 保持接口兼容\n",
    "        else:\n",
    "            return self.enhancer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b9cc6ce-ee42-4639-9f53-6a1c97fc7231",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetinexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RetinexNet, self).__init__()\n",
    "        self.DecomNet = DecomNet()\n",
    "\n",
    "    def forward(self, input):\n",
    "        R, I = self.DecomNet(input)\n",
    "        return R, I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2739ef6c-72f8-4b1a-8aa0-3e0ed66b0e5d",
   "metadata": {},
   "source": [
    "# ZeroDCE模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bd39a9-8b42-4619-80f8-4d81d15e3136",
   "metadata": {},
   "source": [
    "#### 基于 PyTorch 的轻量级图像增强模块，通过深度学习技术提升低光照图像的质量。其核心方法是将输入图像分解为反射率（R）和光照（I）两个部分，并通过调整光照生成增强图像，适用于夜间目标检测等场景。模块包含以下关键函数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6a92e-0181-4699-8c64-dc06da50b978",
   "metadata": {},
   "source": [
    "## __init__ 函数\n",
    "#### 该函数初始化 ZeroDCE 模型，定义了一个包含 8 层卷积的网络，通道数从 3（RGB 输入）逐步增加到 128，再减少到 4（3 通道反射率 R 和 1 通道光照 I），并设置 ReLU 激活函数以提取非线性特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc5e12-e306-41a2-a6dc-bdb513dc9247",
   "metadata": {},
   "source": [
    "## forward 函数\n",
    "#### forward 函数执行前向传播，将输入图像通过卷积层处理，分解为反射率 R 和光照 I（使用 sigmoid 激活限制范围在 [0, 1]），随后调整光照 I（例如乘以 1.5 并裁剪），最后通过 R 和调整后的 I 相乘生成增强图像，返回增强图像、R 和 I。\n",
    "\n",
    "## loss 函数\n",
    "#### loss 函数定义了训练时的损失计算，包括重建损失（确保 R 和 I 重构原始图像）、互重建损失（增强 R 和 I 的独立性）、反射率一致性损失（强制低光和高光图像的 R 相似）以及光照平滑损失（确保 I 平滑），通过加权组合优化分解和增强质量。\n",
    "\n",
    "## smooth 函数\n",
    "#### smooth 函数实现光照平滑损失，首先将反射率 R 转换为灰度图，然后计算光照 I 在 x 和 y 方向上的加权梯度（加权基于 R 的灰度梯度），最后返回梯度的平均值，确保光照 I 在非边缘区域平滑，同时在边缘处保留细节。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40b02290-11bc-405d-8135-9ba21bb29d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroDCE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # 定义卷积层：逐步增加和减少通道数\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 64, 3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(64, 32, 3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(32, 16, 3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(16, 8, 3, stride=1, padding=1)\n",
    "        \n",
    "        # 输出层：输出 4 通道（R 3 通道 + I 1 通道）\n",
    "        self.conv8 = nn.Conv2d(8, 4, 3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 前向传播\n",
    "        x1 = self.relu(self.conv1(x))\n",
    "        x2 = self.relu(self.conv2(x1))\n",
    "        x3 = self.relu(self.conv3(x2))\n",
    "        x4 = self.relu(self.conv4(x3))\n",
    "        x5 = self.relu(self.conv5(x4))\n",
    "        x6 = self.relu(self.conv6(x5))\n",
    "        x7 = self.relu(self.conv7(x6))\n",
    "        \n",
    "        # 分解输出：4 通道分为 R（前 3 通道）和 I（第 4 通道）\n",
    "        decomposition = self.conv8(x7)\n",
    "        R = torch.sigmoid(decomposition[:, :3, :, :])  # 反射率 R，3 通道，范围 [0, 1]\n",
    "        I = torch.sigmoid(decomposition[:, 3:4, :, :])  # 光照 I，单通道，范围 [0, 1]\n",
    "        \n",
    "        # 调整光照 I（示例：提升亮度）\n",
    "        adjusted_I = I * 1.5  # 可根据需求调整倍数\n",
    "        adjusted_I = torch.clamp(adjusted_I, 0, 1)  # 限制在 [0, 1] 范围内\n",
    "        \n",
    "        # 生成增强图像\n",
    "        enhanced = R * adjusted_I\n",
    "        return enhanced, R, I\n",
    "\n",
    "    def loss(self, R_low, I_low, R_high, I_high, input_low, input_high):\n",
    "        # 重建损失：确保 R * I 重建输入图像\n",
    "        recon_loss_low = F.l1_loss(R_low * I_low, input_low)\n",
    "        recon_loss_high = F.l1_loss(R_high * I_high, input_high)\n",
    "        \n",
    "        # 互重建损失：增强跨域一致性\n",
    "        recon_loss_mutal_low = F.l1_loss(R_high * I_low, input_low)\n",
    "        recon_loss_mutal_high = F.l1_loss(R_low * I_high, input_high)\n",
    "        \n",
    "        # 反射率一致性损失：低光和高光图像的 R 应相似\n",
    "        equal_R_loss = F.l1_loss(R_low, R_high.detach())\n",
    "        \n",
    "        # 光照平滑损失：确保 I 在空间上平滑\n",
    "        Ismooth_loss_low = self.smooth(I_low, R_low)\n",
    "        Ismooth_loss_high = self.smooth(I_high, R_high)\n",
    "\n",
    "        # 总损失：加权组合\n",
    "        loss = (recon_loss_low +\n",
    "                recon_loss_high +\n",
    "                0.001 * recon_loss_mutal_low +\n",
    "                0.001 * recon_loss_mutal_high +\n",
    "                0.1 * Ismooth_loss_low +\n",
    "                0.1 * Ismooth_loss_high +\n",
    "                0.01 * equal_R_loss)\n",
    "        return loss\n",
    "\n",
    "    def gradient(self, input_tensor, direction):\n",
    "        \"\"\"计算梯度，用于光照平滑损失\"\"\"\n",
    "        smooth_kernel_x = torch.FloatTensor([[0, 0], [-1, 1]]).view((1, 1, 2, 2)).to(input_tensor.device)\n",
    "        smooth_kernel_y = torch.transpose(smooth_kernel_x, 2, 3)\n",
    "        kernel = smooth_kernel_x if direction == \"x\" else smooth_kernel_y\n",
    "        grad_out = torch.abs(F.conv2d(input_tensor, kernel, stride=1, padding=1))\n",
    "        return grad_out\n",
    "\n",
    "    def ave_gradient(self, input_tensor, direction):\n",
    "        \"\"\"计算平均梯度\"\"\"\n",
    "        return F.avg_pool2d(self.gradient(input_tensor, direction), kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def smooth(self, input_I, input_R):\n",
    "        \"\"\"光照平滑损失函数\"\"\"\n",
    "        # 将 R 转换为灰度图，用于指导光照平滑\n",
    "        input_R_gray = 0.299 * input_R[:, 0, :, :] + 0.587 * input_R[:, 1, :, :] + 0.114 * input_R[:, 2, :, :]\n",
    "        input_R_gray = torch.unsqueeze(input_R_gray, dim=1)\n",
    "        \n",
    "        # 计算光照的梯度并根据 R 加权\n",
    "        grad_x = self.gradient(input_I, \"x\") * torch.exp(-10 * self.ave_gradient(input_R_gray, \"x\"))\n",
    "        grad_y = self.gradient(input_I, \"y\") * torch.exp(-10 * self.ave_gradient(input_R_gray, \"y\"))\n",
    "        return torch.mean(grad_x + grad_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2023",
   "language": "python",
   "name": "pytorch2023"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
