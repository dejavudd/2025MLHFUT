{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在终端输入：python -m torch.distributed.launch --nproc_per_node=1 train.py --enhancer=zerodce 以采用ZeroDCE模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import torch\n",
    "import argparse\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "\n",
    "from data.config import cfg\n",
    "from layers.modules import MultiBoxLoss, EnhanceLoss\n",
    "from data.widerface import WIDERDetection, detection_collate\n",
    "from models.factory import build_net, basenet_factory\n",
    "from models.enhancer import RetinexNet, ZeroDCE\n",
    "from utils.DarkISP import Low_Illumination_Degrading\n",
    "from PIL import Image\n",
    "\n",
    "# 参数解析\n",
    "parser = argparse.ArgumentParser(\n",
    "    description='DSFD face Detector Training With Pytorch')\n",
    "train_set = parser.add_mutually_exclusive_group()\n",
    "parser.add_argument('--batch_size',\n",
    "                    default=4, type=int,\n",
    "                    help='Batch size for training')\n",
    "parser.add_argument('--model',\n",
    "                    default='dark', type=str,\n",
    "                    choices=['dark', 'vgg', 'resnet50', 'resnet101', 'resnet152'],\n",
    "                    help='model for training')\n",
    "parser.add_argument('--resume',\n",
    "                    default=None, type=str,\n",
    "                    help='Checkpoint state_dict file to resume training from')\n",
    "parser.add_argument('--num_workers',\n",
    "                    default=0, type=int,\n",
    "                    help='Number of workers used in dataloading')\n",
    "parser.add_argument('--cuda',\n",
    "                    default=True, type=bool,\n",
    "                    help='Use CUDA to train model')\n",
    "parser.add_argument('--lr', '--learning-rate',\n",
    "                    default=5e-4, type=float,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum',\n",
    "                    default=0.9, type=float,\n",
    "                    help='Momentum value for optim')\n",
    "parser.add_argument('--weight_decay',\n",
    "                    default=5e-4, type=float,\n",
    "                    help='Weight decay for SGD')\n",
    "parser.add_argument('--gamma',\n",
    "                    default=0.1, type=float,\n",
    "                    help='Gamma update for SGD')\n",
    "parser.add_argument('--multigpu',\n",
    "                    default=True, type=bool,\n",
    "                    help='Use mutil Gpu training')\n",
    "parser.add_argument('--save_folder',\n",
    "                    default='weights/',\n",
    "                    help='Directory for saving checkpoint models')\n",
    "parser.add_argument('--local_rank',\n",
    "                    type=int,\n",
    "                    help='local rank for dist')\n",
    "parser.add_argument('--enhancer',\n",
    "                    default='retinex', type=str,\n",
    "                    choices=['retinex', 'zerodce'],\n",
    "                    help='enhancer type for training')\n",
    "\n",
    "args = parser.parse_args()\n",
    "global local_rank\n",
    "local_rank = args.local_rank\n",
    "\n",
    "# 设置环境变量以支持分布式训练\n",
    "if 'LOCAL_RANK' not in os.environ:\n",
    "    os.environ['LOCAL_RANK'] = str(args.local_rank)\n",
    "\n",
    "# 初始化分布式进程组\n",
    "import torch.distributed as dist\n",
    "dist.init_process_group(backend='nccl')\n",
    "\n",
    "# 检查 GPU 可用性并设置设备\n",
    "if torch.cuda.is_available():\n",
    "    if args.cuda:\n",
    "        gpu_num = torch.cuda.device_count()\n",
    "        if local_rank == 0:\n",
    "            print('Using {} gpus'.format(gpu_num))\n",
    "        rank = int(os.environ['RANK'])\n",
    "        torch.cuda.set_device(rank % gpu_num)\n",
    "    if not args.cuda:\n",
    "        print(\"WARNING: It looks like you have a CUDA device, but aren't \" +\n",
    "              \"using CUDA.\\nRun with --cuda for optimal training speed.\")\n",
    "        torch.set_default_tensor_type('torch.FloatTensor')\n",
    "else:\n",
    "    torch.set_default_tensor_type('torch.FloatTensor')\n",
    "\n",
    "# 设置保存路径\n",
    "save_folder = os.path.join(args.save_folder, args.model)\n",
    "if not os.path.exists(save_folder):\n",
    "    os.mkdir(save_folder)\n",
    "\n",
    "# 数据加载器\n",
    "train_dataset = WIDERDetection(cfg.FACE.TRAIN_FILE, mode='train')\n",
    "val_dataset = WIDERDetection(cfg.FACE.VAL_FILE, mode='val')\n",
    "train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, shuffle=True)\n",
    "train_loader = data.DataLoader(train_dataset, args.batch_size,\n",
    "                               num_workers=args.num_workers,\n",
    "                               collate_fn=detection_collate,\n",
    "                               sampler=train_sampler,\n",
    "                               pin_memory=True)\n",
    "val_batchsize = args.batch_size\n",
    "val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=True)\n",
    "val_loader = data.DataLoader(val_dataset, val_batchsize,\n",
    "                             num_workers=0,\n",
    "                             collate_fn=detection_collate,\n",
    "                             sampler=val_sampler,\n",
    "                             pin_memory=True)\n",
    "\n",
    "min_loss = np.inf\n",
    "\n",
    "def train():\n",
    "    per_epoch_size = len(train_dataset) // (args.batch_size * torch.cuda.device_count())\n",
    "    start_epoch = 0\n",
    "    iteration = 0\n",
    "    step_index = 0\n",
    "\n",
    "    # 模型初始化\n",
    "    basenet = basenet_factory(args.model)\n",
    "    dsfd_net = build_net('train', cfg.NUM_CLASSES, args.model)\n",
    "    net = dsfd_net\n",
    "    if args.enhancer == 'zerodce':\n",
    "        net_enh = ZeroDCE()\n",
    "    else:\n",
    "        net_enh = RetinexNet()\n",
    "        net_enh.load_state_dict(torch.load(args.save_folder + 'decomp.pth'))\n",
    "\n",
    "    # 加载预训练权重或恢复训练\n",
    "    if args.resume:\n",
    "        if local_rank == 0:\n",
    "            print('Resuming training, loading {}...'.format(args.resume))\n",
    "        start_epoch = net.load_weights(args.resume)\n",
    "        iteration = start_epoch * per_epoch_size\n",
    "    else:\n",
    "        base_weights = torch.load(args.save_folder + basenet)\n",
    "        if local_rank == 0:\n",
    "            print('Load base network {}'.format(args.save_folder + basenet))\n",
    "        if args.model == 'vgg' or args.model == 'dark':\n",
    "            net.vgg.load_state_dict(base_weights)\n",
    "        else:\n",
    "            net.resnet.load_state_dict(base_weights)\n",
    "\n",
    "    # 初始化网络权重\n",
    "    if not args.resume:\n",
    "        if local_rank == 0:\n",
    "            print('Initializing weights...')\n",
    "        net.extras.apply(net.weights_init)\n",
    "        net.fpn_topdown.apply(net.weights_init)\n",
    "        net.fpn_latlayer.apply(net.weights_init)\n",
    "        net.fpn_fem.apply(net.weights_init)\n",
    "        net.loc_pal1.apply(net.weights_init)\n",
    "        net.conf_pal1.apply(net.weights_init)\n",
    "        net.loc_pal2.apply(net.weights_init)\n",
    "        net.conf_pal2.apply(net.weights_init)\n",
    "        net.ref.apply(net.weights_init)\n",
    "\n",
    "    # 设置学习率\n",
    "    lr = args.lr * np.round(np.sqrt(args.batch_size / 4 * torch.cuda.device_count()), 4)\n",
    "    param_group = []\n",
    "    param_group += [{'params': dsfd_net.vgg.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.extras.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.fpn_topdown.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.fpn_latlayer.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.fpn_fem.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.loc_pal1.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.conf_pal1.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.loc_pal2.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.conf_pal2.parameters(), 'lr': lr}]\n",
    "    param_group += [{'params': dsfd_net.ref.parameters(), 'lr': lr / 10.}]\n",
    "\n",
    "    optimizer = optim.SGD(param_group, lr=lr, momentum=args.momentum,\n",
    "                          weight_decay=args.weight_decay)\n",
    "\n",
    "    # 将模型移到 GPU 并启用分布式训练\n",
    "    if args.cuda:\n",
    "        if args.multigpu:\n",
    "            net = torch.nn.parallel.DistributedDataParallel(net.cuda(), find_unused_parameters=True)\n",
    "            net_enh = torch.nn.parallel.DistributedDataParallel(net_enh.cuda())\n",
    "        cudnn.benchmark = True\n",
    "\n",
    "    criterion = MultiBoxLoss(cfg, args.cuda)\n",
    "    criterion_enhance = EnhanceLoss()\n",
    "    if local_rank == 0:\n",
    "        print('Loading wider dataset...')\n",
    "        print('Using the specified args:')\n",
    "        print(args)\n",
    "\n",
    "    # 调整学习率\n",
    "    for step in cfg.LR_STEPS:\n",
    "        if iteration > step:\n",
    "            step_index += 1\n",
    "            adjust_learning_rate(optimizer, args.gamma, step_index)\n",
    "\n",
    "    net_enh.eval()\n",
    "    net.train()\n",
    "    for epoch in range(start_epoch, cfg.EPOCHES):\n",
    "        losses = 0\n",
    "\n",
    "        for batch_idx, (images, targets, _) in enumerate(train_loader):\n",
    "            images = Variable(images.cuda() / 255.)\n",
    "            targetss = [Variable(ann.cuda(), requires_grad=False) for ann in targets]\n",
    "            img_dark = torch.empty(size=(images.shape[0], images.shape[1], images.shape[2], images.shape[3])).cuda()\n",
    "            for i in range(images.shape[0]):\n",
    "                img_dark[i], _ = Low_Illumination_Degrading(images[i])\n",
    "\n",
    "            if iteration in cfg.LR_STEPS:\n",
    "                step_index += 1\n",
    "                adjust_learning_rate(optimizer, args.gamma, step_index)\n",
    "\n",
    "            t0 = time.time()\n",
    "            if args.enhancer == 'zerodce':\n",
    "                enhanced_dark, R_dark_gt, I_dark = net_enh(img_dark)\n",
    "                enhanced_light, R_light_gt, I_light = net_enh(images)\n",
    "            else:\n",
    "                R_dark_gt, I_dark = net_enh(img_dark)\n",
    "                R_light_gt, I_light = net_enh(images)\n",
    "                enhanced_dark = R_dark_gt * I_dark\n",
    "                enhanced_light = R_light_gt * I_light\n",
    "\n",
    "            out, out2, loss_mutual = net(img_dark, images, I_dark.detach(), I_light.detach())\n",
    "            R_dark, R_light, R_dark_2, R_light_2 = out2\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            loss_l_pa1l, loss_c_pal1 = criterion(out[:3], targetss)\n",
    "            loss_l_pa12, loss_c_pal2 = criterion(out[3:], targetss)\n",
    "            loss_enhance = criterion_enhance([R_dark, R_light, R_dark_2, R_light_2, I_dark.detach(), I_light.detach()], images, img_dark) * 0.1\n",
    "            loss_enhance2 = F.l1_loss(R_dark, R_dark_gt.detach()) + F.l1_loss(R_light, R_light_gt.detach()) + (\n",
    "                        1. - ssim(R_dark, R_dark_gt.detach())) + (1. - ssim(R_light, R_light_gt.detach()))\n",
    "\n",
    "            loss = loss_l_pa1l + loss_c_pal1 + loss_l_pa12 + loss_c_pal2 + loss_enhance2 + loss_enhance + loss_mutual\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=35, norm_type=2)\n",
    "            optimizer.step()\n",
    "            t1 = time.time()\n",
    "            losses += loss.item()\n",
    "\n",
    "            if iteration % 100 == 0:\n",
    "                tloss = losses / (batch_idx + 1)\n",
    "                if local_rank == 0:\n",
    "                    print('Timer: %.4f' % (t1 - t0))\n",
    "                    print('epoch:' + repr(epoch) + ' || iter:' +\n",
    "                          repr(iteration) + ' || Loss:%.4f' % (tloss))\n",
    "                    print('->> pal1 conf loss:{:.4f} || pal1 loc loss:{:.4f}'.format(\n",
    "                        loss_c_pal1.item(), loss_l_pa1l.item()))\n",
    "                    print('->> pal2 conf loss:{:.4f} || pal2 loc loss:{:.4f}'.format(\n",
    "                        loss_c_pal2.item(), loss_l_pa12.item()))\n",
    "                    print('->>lr:{}'.format(optimizer.param_groups[0]['lr']))\n",
    "\n",
    "            if iteration != 0 and iteration % 5000 == 0:\n",
    "                if local_rank == 0:\n",
    "                    print('Saving state, iter:', iteration)\n",
    "                    file = 'dsfd_' + repr(iteration) + '.pth'\n",
    "                    torch.save(dsfd_net.state_dict(),\n",
    "                               os.path.join(save_folder, file))\n",
    "            iteration += 1\n",
    "\n",
    "        if (epoch + 1) >= 0:\n",
    "            val(epoch, net, dsfd_net, net_enh, criterion)\n",
    "        if iteration >= cfg.MAX_STEPS:\n",
    "            break\n",
    "\n",
    "def val(epoch, net, dsfd_net, net_enh, criterion):\n",
    "    net.eval()\n",
    "    step = 0\n",
    "    losses = torch.tensor(0.).cuda()\n",
    "    t1 = time.time()\n",
    "\n",
    "    for batch_idx, (images, targets, img_paths) in enumerate(val_loader):\n",
    "        if args.cuda:\n",
    "            images = Variable(images.cuda() / 255.)\n",
    "            targets = [Variable(ann.cuda(), volatile=True) for ann in targets]\n",
    "        else:\n",
    "            images = Variable(images / 255.)\n",
    "            targets = [Variable(ann, volatile=True) for ann in targets]\n",
    "        img_dark = torch.stack([Low_Illumination_Degrading(images[i])[0] for i in range(images.shape[0])], dim=0)\n",
    "        out, R = net.module.test_forward(img_dark)\n",
    "\n",
    "        loss_l_pa1l, loss_c_pal1 = criterion(out[:3], targets)\n",
    "        loss_l_pa12, loss_c_pal2 = criterion(out[3:], targets)\n",
    "        loss = loss_l_pa12 + loss_c_pal2\n",
    "\n",
    "        losses += loss.item()\n",
    "        step += 1\n",
    "    dist.reduce(losses, 0, op=dist.ReduceOp.SUM)\n",
    "\n",
    "    tloss = losses / step / torch.cuda.device_count()\n",
    "    t2 = time.time()\n",
    "    if local_rank == 0:\n",
    "        print('Timer: %.4f' % (t2 - t1))\n",
    "        print('test epoch:' + repr(epoch) + ' || Loss:%.4f' % (tloss))\n",
    "\n",
    "    global min_loss\n",
    "    if tloss < min_loss:\n",
    "        if local_rank == 0:\n",
    "            print('Saving best state,epoch', epoch)\n",
    "            torch.save(dsfd_net.state_dict(), os.path.join(save_folder, 'dsfd.pth'))\n",
    "        min_loss = tloss\n",
    "\n",
    "    states = {\n",
    "        'epoch': epoch,\n",
    "        'weight': dsfd_net.state_dict(),\n",
    "    }\n",
    "    if local_rank == 0:\n",
    "        torch.save(states, os.path.join(save_folder, 'dsfd_checkpoint.pth'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, gamma, step):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 at every specified step\"\"\"\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = param_group['lr'] * gamma\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
