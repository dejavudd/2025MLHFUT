{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37eecea7-d61e-444f-b65b-d26a2c004f3e",
   "metadata": {},
   "source": [
    "# 模块导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752dc178-1a43-478f-ba1f-395c46715999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import math\n",
    "from timm.models.vision_transformer import VisionTransformer, _cfg\n",
    "from timm.models.registry import register_model\n",
    "from timm.models.layers import trunc_normal_, DropPath, to_2tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f519a6ae-c194-4aad-b9b1-b9090d68dee4",
   "metadata": {},
   "source": [
    "# 自定义归一化模块 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b493be-f8bb-4af0-9976-227a6841e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Aff(nn.Module):\n",
    "    \"\"\"\n",
    "    简单仿射归一化：输出 = 输入 * α + β\n",
    "    α、β均为可训练参数\n",
    "    \"\"\"\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones([1, 1, dim]))\n",
    "        self.beta = nn.Parameter(torch.zeros([1, 1, dim]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.alpha + self.beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ae273-5f56-4484-aeaa-80b7f8225adf",
   "metadata": {},
   "source": [
    "# 自定义颜色归一化模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45359dc3-0af4-468f-8f09-b9e29e0f7c8a",
   "metadata": {},
   "source": [
    "class Aff_channel(nn.Module):\n",
    "    \"\"\"\n",
    "    增加颜色变换矩阵的仿射归一化：可模拟全局色彩调整\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, channel_first=True):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones([1, 1, dim]))\n",
    "        self.beta = nn.Parameter(torch.zeros([1, 1, dim]))\n",
    "        self.color = nn.Parameter(torch.eye(dim))  # 初始为单位矩阵\n",
    "        self.channel_first = channel_first\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.channel_first:\n",
    "            x1 = torch.tensordot(x, self.color, dims=[[-1], [-1]])\n",
    "            x2 = x1 * self.alpha + self.beta\n",
    "        else:\n",
    "            x1 = x * self.alpha + self.beta\n",
    "            x2 = torch.tensordot(x1, self.color, dims=[[-1], [-1]])\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b878a2f0-9f08-4e31-8269-8a7edf55dea6",
   "metadata": {},
   "source": [
    "#  MLP结构 (全连接版本)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf9a10f-f4dd-472b-bc9b-8b7b56c21d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    \"\"\"\n",
    "    标准多层感知机模块，包含两层全连接和GELU激活\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd2f68-7829-45aa-b0c6-cfbe17a372f7",
   "metadata": {},
   "source": [
    "# 卷积版 MLP结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc117b60-1e99-4396-82f6-c5af05023ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMlp(nn.Module):\n",
    "    \"\"\"\n",
    "    卷积版多层感知机，适配CNN通道输入\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Conv2d(in_features, hidden_features, 1)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Conv2d(hidden_features, out_features, 1)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b46da00-316d-4ae8-bbe1-16eaffbfb748",
   "metadata": {},
   "source": [
    "# CNN模块 CBlock_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1342f2-7013-4f34-84ce-0065d0c97aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBlock_ln(nn.Module):\n",
    "    \"\"\"\n",
    "    CNN基本模块：包含位置卷积+通道注意力+残差连接+MLP\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, mlp_ratio=4., qkv_bias=False, qk_scale=None, drop=0.,\n",
    "                 attn_drop=0., drop_path=0., act_layer=nn.GELU, norm_layer=Aff_channel, init_values=1e-4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.pos_embed = nn.Conv2d(dim, dim, 3, padding=1, groups=dim)\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.conv1 = nn.Conv2d(dim, dim, 1)\n",
    "        self.conv2 = nn.Conv2d(dim, dim, 1)\n",
    "        self.attn = nn.Conv2d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.gamma_1 = nn.Parameter(init_values * torch.ones((1, dim, 1, 1)), requires_grad=True)\n",
    "        self.gamma_2 = nn.Parameter(init_values * torch.ones((1, dim, 1, 1)), requires_grad=True)\n",
    "        self.mlp = CMlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 残差加位置编码\n",
    "        x = x + self.pos_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "        norm_x = x.flatten(2).transpose(1, 2)\n",
    "        norm_x = self.norm1(norm_x).view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "\n",
    "        # 局部注意力卷积分支\n",
    "        x = x + self.drop_path(self.gamma_1 * self.conv2(self.attn(self.conv1(norm_x))))\n",
    "        norm_x = x.flatten(2).transpose(1, 2)\n",
    "        norm_x = self.norm2(norm_x).view(B, H, W, C).permute(0, 3, 1, 2)\n",
    "\n",
    "        # MLP分支\n",
    "        x = x + self.drop_path(self.gamma_2 * self.mlp(norm_x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fde5e-ace9-447c-af2d-306b9ae8a34a",
   "metadata": {},
   "source": [
    "# Swin Transformer核心模块：窗口划分与重组"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539a2b2b-8383-46b4-839d-09ae9fb84ce5",
   "metadata": {},
   "source": [
    "def window_partition(x, window_size):\n",
    "    \"\"\"\n",
    "    图像窗口划分函数：将特征图划分成多个小窗口\n",
    "    输入形状 (B, H, W, C)\n",
    "    输出形状 (num_windows*B, window_size, window_size, C)\n",
    "    \"\"\"\n",
    "    B, H, W, C = x.shape\n",
    "    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)\n",
    "    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)\n",
    "    return windows\n",
    "\n",
    "def window_reverse(windows, window_size, H, W):\n",
    "    \"\"\"\n",
    "    将划分窗口后的特征重新拼接回原图大小\n",
    "    \"\"\"\n",
    "    B = int(windows.shape[0] / (H * W / window_size / window_size))\n",
    "    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)\n",
    "    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8e80af-5c6b-4bf2-b244-a66497d009b9",
   "metadata": {},
   "source": [
    "# 窗口内自注意力模块\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03beb3e7-496f-403d-b211-7fdc624eb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer中的窗口注意力机制（标准多头注意力）\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, window_size, num_heads, qkv_bias=True, qk_scale=None, attn_drop=0., proj_drop=0.):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.window_size = window_size\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = qk_scale or head_dim ** -0.5\n",
    "\n",
    "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim, dim)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B_, N, C = x.shape\n",
    "        qkv = self.qkv(x).reshape(B_, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
    "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
    "\n",
    "        q = q * self.scale\n",
    "        attn = (q @ k.transpose(-2, -1))\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = (attn @ v).transpose(1, 2).reshape(B_, N, C)\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be027e-3663-4cdf-a9e9-6e92d2b73b72",
   "metadata": {},
   "source": [
    "#  Swin Transformer Block模块\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d0a19f-91bb-4c58-9ffd-7ea5b2d35d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SwinTransformerBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Swin Transformer核心块（单层窗口注意力+残差+MLP）\n",
    "    \"\"\"\n",
    "    def __init__(self, dim, num_heads=2, window_size=8, shift_size=0,\n",
    "                 mlp_ratio=4., qkv_bias=True, qk_scale=None, drop=0., attn_drop=0., drop_path=0.,\n",
    "                 act_layer=nn.GELU, norm_layer=Aff_channel):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dim = dim\n",
    "        self.num_heads = num_heads\n",
    "        self.window_size = window_size\n",
    "        self.shift_size = shift_size\n",
    "\n",
    "        self.pos_embed = nn.Conv2d(dim, dim, 3, padding=1, groups=dim)\n",
    "        self.norm1 = norm_layer(dim)\n",
    "        self.attn = WindowAttention(\n",
    "            dim, window_size=to_2tuple(self.window_size), num_heads=num_heads,\n",
    "            qkv_bias=qkv_bias, qk_scale=qk_scale, attn_drop=attn_drop, proj_drop=drop)\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pos_embed(x)\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm1(x).view(B, H, W, C)\n",
    "\n",
    "        # 窗口划分与循环位移\n",
    "        if self.shift_size > 0:\n",
    "            shifted_x = torch.roll(x, shifts=(-self.shift_size, -self.shift_size), dims=(1, 2))\n",
    "        else:\n",
    "            shifted_x = x\n",
    "\n",
    "        x_windows = window_partition(shifted_x, self.window_size).view(-1, self.window_size * self.window_size, C)\n",
    "        attn_windows = self.attn(x_windows)\n",
    "        attn_windows = attn_windows.view(-1, self.window_size, self.window_size, C)\n",
    "        shifted_x = window_reverse(attn_windows, self.window_size, H, W)\n",
    "\n",
    "        x = shifted_x.view(B, H * W, C)\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
    "\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lin",
   "language": "python",
   "name": "lin"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
